{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "g3yeJGnCYxuF"
   },
   "source": [
    "<img src=\"https://github.com/hernancontigiani/ceia_memorias_especializacion/raw/master/Figures/logoFIUBA.jpg\" width=\"500\" align=\"center\">\n",
    "\n",
    "\n",
    "# Procesamiento de lenguaje natural\n",
    "## Modelo de lenguaje con tokenización por caracteres"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Iv5PEwGzZA9-"
   },
   "source": [
    "### Consigna\n",
    "- Seleccionar un corpus de texto sobre el cual entrenar el modelo de lenguaje.\n",
    "- Realizar el pre-procesamiento adecuado para tokenizar el corpus, estructurar el dataset y separar entre datos de entrenamiento y validación.\n",
    "- Proponer arquitecturas de redes neuronales basadas en unidades recurrentes para implementar un modelo de lenguaje.\n",
    "- Con el o los modelos que consideren adecuados, generar nuevas secuencias a partir de secuencias de contexto con las estrategias de greedy search y beam search determístico y estocástico. En este último caso observar el efecto de la temperatura en la generación de secuencias.\n",
    "\n",
    "\n",
    "### Sugerencias\n",
    "- Durante el entrenamiento, guiarse por el descenso de la perplejidad en los datos de validación para finalizar el entrenamiento. Para ello se provee un callback.\n",
    "- Explorar utilizar SimpleRNN (celda de Elman), LSTM y GRU.\n",
    "- rmsprop es el optimizador recomendado para la buena convergencia. No obstante se pueden explorar otros.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "Y-QdFbHZYj7C"
   },
   "outputs": [],
   "source": [
    "import random\n",
    "import io\n",
    "import pickle\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "from keras.utils import to_categorical\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, LSTM, Embedding, Dropout\n",
    "from tensorflow.keras.losses import SparseCategoricalCrossentropy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "xTvXlEKQZdqx"
   },
   "source": [
    "### Datos\n",
    "Utilizaremos como dataset canciones de bandas de habla inglés."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# descargar de textos.info\n",
    "import urllib.request\n",
    "\n",
    "# Para leer y parsear el texto en HTML de wikipedia\n",
    "import bs4 as bs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "7amy6uUaBLVD"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "El Gaucho Martín Fierro\n",
      "José Hernández\n",
      "\n",
      "1\n",
      "\n",
      "\f",
      "Texto núm. 4187\n",
      "Título: El Gaucho Martín Fierro\n",
      "Autor: José Hernández\n",
      "Etiquetas: Poesía\n",
      "Editor: Edu Robsy\n",
      "Fecha de creación: 13 de enero de 2019\n",
      "Fecha de modificación: 13 de enero de 2019\n",
      "Edita textos.info\n",
      "Maison Carrée\n",
      "c/ Ramal, 48\n",
      "07730 Alayor - Menorca\n",
      "Islas Baleares\n",
      "España\n",
      "\n",
      "\n",
      "\n",
      "2\n",
      "\n",
      "\f",
      "I\n",
      "Aquí me pongo a cantar\n",
      "al compás de la vigüela,\n",
      "que el hombre que lo desvela\n",
      "una pena estrordinaria,\n",
      "como la ave solitaria\n",
      "con el cantar se consuela.\n",
      "Pido a los Santos d\n"
     ]
    }
   ],
   "source": [
    "# Abrir y leer el contenido del archivo 'martin_fierro.txt'\n",
    "with open('martin_fierro.txt', 'r', encoding='utf-8') as file:\n",
    "    texto = file.read()\n",
    "\n",
    "# Mostrar los primeros 500 caracteres para verificar que se cargó bien\n",
    "print(texto[:500])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "WBE0sSYuB-E6"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'El Gaucho Martín Fierro\\nJosé Hernández\\n\\n1\\n\\n\\x0cTexto núm. 4187\\nTítulo: El Gaucho Martín Fierro\\nAutor: José Hernández\\nEtiquetas: Poesía\\nEditor: Edu Robsy\\nFecha de creación: 13 de enero de 2019\\nFecha de modificación: 13 de enero de 2019\\nEdita textos.info\\nMaison Carrée\\nc/ Ramal, 48\\n07730 Alayor - Menorca\\nIslas Baleares\\nEspaña\\n\\n\\n\\n2\\n\\n\\x0cI\\nAquí me pongo a cantar\\nal compás de la vigüela,\\nque el hombre que lo desvela\\nuna pena estrordinaria,\\ncomo la ave solitaria\\ncon el cantar se consuela.\\nPido a los Santos del Cielo\\nque ayuden mi pensamiento,\\nles pido en este momento\\nque voy a cantar mi historia\\nme refresquen la memoria\\ny aclaren mi entendimiento.\\nVengan Santos milagrosos,\\nvengan todos en mi ayuda,\\nque la lengua se me añuda\\ny se me turba la vista;\\npido a mi Dios que me asista\\nen una ocasión tan ruda.\\nYo he visto muchos cantores,\\ncon famas bien otenidas,\\ny que después de alquiridas\\nno las quieren sustentarparece que sin largar\\nse cansaron en partidas.\\nMas ande otro criollo pasa\\nMartín Fierro ha de pasar,\\nnada lo hace recular\\nni las fantasmas lo espantan;\\ny dende que todos cantan\\nyo también quiero cantar.\\n\\n3\\n\\n\\x0cCantando me he de morir,\\ncantando me han de enterrar,\\ny cantando he de llegar\\nal pie del Eterno Padredende el vientre de mi madre\\nvine a este mundo a cantar.\\nQue no se trabe mi lengua\\nni me falte la palabrael cantar mi gloria labra\\ny poniéndome a cantar\\ncantando me han de encontrar\\naunque la tierra se abra.\\nMe siento en el plan de un bajo\\na cantar un argumentocomo si soplara el viento\\nhago tiritar los pastoscon oros, copas y bastos,\\njuega allí mi pensamiento.\\nYo no soy cantor letrao,\\nmas si me pongo a cantar\\nno tengo cuándo acabar\\ny me envejezco cantando,\\nlas coplas me van brotando\\ncomo agua de manantial.\\nCon la guitarra en la mano\\nni las moscas se me arriman,\\nnaides me pone el pie encima,\\ny cuando el pecho se entona,\\nhago gemir a la prima\\ny llorar a la bordona.\\nYo soy toro en mi rodeo,\\ny toraso en rodeo ajeno,\\nsiempre me tuve por güeno\\ny si me quieren probar\\nsalgan otros a cantar\\n\\n4\\n\\n\\x0cy veremos quién es menos.\\nNo me hago al lao de la güeya\\naunque venga degollando,\\ncon los blandos yo soy blando,\\ny soy duro con los duros,\\ny ninguno, en un apuro\\nme ha visto andar tutubiando\\nEn el peligro ¡Qué Cristos!\\nel corazón se me enancha\\npues toda la tierra es cancha,\\ny de esto naides se asombre,\\nel que se tiene por hombre\\ndonde quiera hace pata ancha.\\nSoy gaucho, y entiendanló\\ncomo mi lengua lo esplica,\\npara mí la tierra es chica\\ny pudiera ser mayor,\\nni la víbora me pica\\nni quema mi frente el Sol.\\nNací como nace el peje\\nen el fondo de la mar,\\nnaides me puede quitar\\naquello que Dios me diolo que al mundo truje yo\\ndel mundo lo he de llevar.\\nMi gloria es vivir tan libre\\ncomo el pájaro del Cielo,\\nno hago nido en este suelo\\nande hay tanto que sufrir;\\ny naides me ha de seguir\\ncuando yo remuento el vuelo.\\nYo no tengo en el amor\\nquien me venga con querellas,\\ncomo esas aves tan bellas\\nque saltan de rama en rama-\\n\\n5\\n\\n\\x0cyo hago en el trébol mi cama\\ny me cubren las estrellas.\\nY sepan cuantos me escuchan\\nde mis penas el relato\\nque nunca peleo ni mato\\nsino por necesidad;\\ny que a tanta alversidá\\nsólo me arrojó el mal trato.\\nY atiendan la relación\\nque hace un gaucho perseguido,\\nque padre y marido ha sido\\nempeñoso y diligente,\\ny sin embargo la gente\\nlo tiene por un bandido.\\n\\n6\\n\\n\\x0cII\\nNinguno me hable de penas\\nporque yo penando vivoy naides se muestre altivo\\naunque en el estribo esté,\\nque suele quedarse a pie\\nel gaucho más alvertido.\\nJunta esperencia en la vida\\nhasta pa dar y prestar,\\nquien la tiene que pasar\\nentre sufrimiento y llanto;\\nporque nada enseña tanto\\ncomo el sufrir y el llorar.\\nViene el hombre ciego al mundo\\ncuartiándolo la esperanza\\ny a poco andar ya lo alcanzan\\nlas desgracias a empujones;\\n¡la pucha que trae liciones\\nel tiempo con sus mudanzas!\\nYo he conocido esta tierra\\nen que el paisano vivía\\ny su ranchito tenía\\ny sus hijos y mujer...\\nEra una delicia el ver\\ncómo pasaba sus días.\\nEntonces... cuando el lucero\\nbrillaba en el cielo santo,\\ny los gallos con su canto\\nnos decían que el día llegaba,\\na la cocina rumbiaba\\nel gaucho... que era un encanto.\\n\\n7\\n\\n\\x0cY sentao junto al jogón\\na esperar que venga el día,\\nal cimarrón le prendía\\nhasta ponerse rechoncho,\\nmientras su china dormía\\ntapadita con su poncho.\\nY apenas la madrugada\\nempezaba a coloriar,\\nlos pájaros a cantar,\\ny las gallinas a apiarse,\\nera cosa de largarse\\ncada cual a trabajar.\\nÉste se ata las espuelas,\\nse sale el otro cantando,\\nuno busca un pellón blando,\\néste un lazo, otro un rebenque,\\ny los pingos relinchando\\nlos llaman dende el palenque.\\nEl que era pión domador\\nenderezaba al corral\\nande estaba el animal\\nbufidos que se las pela...\\nY más malo que su agüela,\\nse hacía astillas el bagual.\\nY allí el gaucho inteligente\\nen cuanto el potro enriendó,\\nlos cueros le acomodó\\ny se le sentó en seguida,\\nque el hombre muestra en la vida\\nla astucia que Dios le dio.\\nY en las playas corcobiando\\npedazos se hacía el sotreta,\\nmientras él por las paletas\\nle jugaba las lloronas,\\ny al ruido de las caronas\\n\\n8\\n\\n\\x0csalía haciéndose gambetas.\\n¡Ah tiempos!... Si era un orgullo\\nver jinetiar un paisanoCuando era gaucho vaquiano\\naunque el potro se boliase\\nno había uno que no parase\\ncon el cabresto en la mano.\\nY mientras domaban unos,\\notros al campo salían,\\ny la hacienda recogían,\\nlas manadas repuntaban,\\ny ansí sin sentir pasaban\\nentretenidos el día.\\nY verlos al cair la noche\\nen la cocina riunidos\\ncon el juego bien prendido\\ny mil cosas que contar,\\nplaticar muy divertidos\\nhasta después de cenar.\\nY con el buche bien lleno\\nera cosa superior\\nirse en brazos del amor\\na dormir como la gente,\\npa empezar al día siguiente\\nlas fainas del día anterior.\\n¡Ricuerdo!... ¡Qué maravilla!\\ncómo andaba la gauchada\\nsiempre alegre y bien montada\\ny dispuesta pa el trabajo...\\npero hoy en el día... ¡barajo!\\nno se le ve de aporriada.\\nEl gaucho más infeliz\\ntenía tropilla de un pelo,\\nno le faltaba un consuelo\\ny andaba la gente lista...\\n\\n9\\n\\n\\x0ctendiendo al campo la vista\\nno vía sino hacienda y cielo\\nCuando llegaban las yerras,\\n¡cosa que daba calor!\\ntanto gaucho pialador\\ny tironiador sin yel¡Ah tiempos!... pero sin él\\nse ha visto tanto primor.\\nAquello no era trabajo,\\nmás bien era una junción,\\ny después de un güen tirón\\nen que uno se daba maña\\npa darle un trago de caña\\nsolía llamarlo el patrón.\\nPues siempre la mamajuana\\nvivía bajo la carreta\\ny aquel que no era chancleta\\nen cuanto el goyete vía,\\nsin miedo se le prendía,\\ncomo güérfano a la teta.\\n¡Y qué jugadas se armaban\\ncuando estábamos riunidos!\\nSiempre íbamos prevenidos\\npues en tales ocasiones,\\na ayudarles a los piones\\ncaiban muchos comedidos.\\nEran los días del apuro\\ny alboroto pa el hembraje,\\npa preparar los potajes\\ny osequiar bien a la gente,\\ny ansí, pues, muy grandemente,\\npasaba siempre el gauchaje.\\nVenía la carne con cuero,\\nla sabrosa carbonada,\\nmazamorra bien pisada\\n\\n10\\n\\n\\x0clos pasteles y el güen vino...\\npero ha querido el destino\\nque todo aquello acabara.\\nEstaba el gaucho en su pago\\ncon toda siguridá\\npero aura... ¡barbaridá!\\nla cosa anda tan fruncida\\nque gasta el pobre la vida\\nen juir de la autoridá.\\nPues si usté pisa en su rancho\\ny si el alcalde lo sabe\\nlo caza lo mesmo que ave,\\naunque su mujer aborte...\\n¡No hay tiempo que no se acabe\\nni tiento que no se corte!\\nY al punto dese por muerto\\nsi el alcalde lo bolea,\\npues ay nomás se le apea\\ncon una felpa de palos-,\\ny después dicen que es malo\\nel gaucho si los pelea.\\nY el lomo le hinchan a golpes,\\ny le rompen la cabeza,\\ny luego con ligereza\\nansí lastimao y todo,\\nlo amarran codo con codo\\ny pa el cepo lo enderiezan.\\nAy comienzan sus desgracias\\nay principia el pericón;\\nporque no hay salvación,\\ny que usté quiera o no quiera\\nlo mandan a la frontera\\no lo echan a un batallón.\\n\\n11\\n\\n\\x0cAnsí empezaron mis males\\nlo mesmo que los de tantos\\nsi gustan... en otros cantos\\nles diré lo que he sufridodespués que uno está perdido\\nno lo salvan ni los santos.\\n\\n12\\n\\n\\x0cIII\\nTuve en mi pago en un tiempo\\nhijos, hacienda y mujer,\\npero empecé a padecer\\nme echaron a la frontera,\\n¡y qué iba a hallar al volver!\\nTan sólo hallé la tapera.\\nSosegao vivía en mi rancho\\ncomo el pájaro en su nidoallí mis hijos queridos\\niban creciendo a mi lao...\\nSólo queda al desgraciao\\nlamentar el bien perdido.\\nMi gala en las pulperías\\nera, cuando había más gente,\\nponerme medio caliente,\\npues cuando puntiao me encuentro,\\nme salen coplas de adentro\\ncomo agua de la virtiente.\\nCantando estaba una vez\\nen una gran diversión;\\ny aprovechó la ocasión\\ncomo quiso el Juez de Paz...\\nse presentó, y hay no más,\\nhizo una arriada en montón.\\nJuyeron los más matreros\\ny lograron escaparyo no quise dispararsoy manso- y no había por quémuy tranquilo me quedé\\ny ansí me dejé agarrar.\\n\\n13\\n\\n\\x0cAllí un gringo con un órgano\\ny una mona que bailaba\\nhaciéndonos reir estaba\\ncuando le tocó el arreo¡tan grande el gringo y tan feo!\\nlo viera cómo lloraba.\\nHasta un Inglés sangiador\\nque decía en la última guerra,\\nque él era de Inca-la-perra\\ny que no quería servir,\\ntuvo también que juir\\na guarecerse en la sierra.\\nNi los mirones salvaron\\nde esa arriada de mi florfue acoyarao el cantor\\ncon el gringo de la monaa uno sólo, por favor\\nlogró salvar la patrona.\\nFormaron un contingente\\ncon los que en el baile arriaroncon otros nos mesturaron\\nque habían agarrao tambiénLas cosas que aquí se ven\\nni los diablos las pensaron.\\nA mí el Juez me tomó entre ojos\\nen la última votaciónme le había hecho el remolón\\ny no me arrimé ese día;\\ny él dijo que yo servía\\na los de la esposición.\\nY ansí sufrí ese castigo\\ntal vez por culpas ajenasque sean malas o sean güenas\\nlas listas, siempre me escondoyo soy un gaucho redondo\\n\\n14\\n\\n\\x0cy esas cosas no me enllenan.\\nAl mandarnos nos hicieron\\nmás promesas que a un altarel Juez nos jue a ploclamar\\ny nos dijo muchas veces\\n«muchachos a los seis meses\\n»los van a ir a revelar».\\nYo llevé un moro de número,\\n¡sobresaliente el matucho!\\nCon él gané en Ayacucho,\\nmás plata que agua benditasiempre el gaucho necesita\\nun pingo pa fiarle un pucho-.\\nY cargué sin dar más güeltas\\ncon las prendas que tenía,\\njergas, poncho, cuanto había\\nen casa, tuito lo alcéa m'"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# en article text se encuentra el texto de todo el libro\n",
    "texto[:10000]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "cP1JdiOIKQWi"
   },
   "source": [
    "### Elegir el tamaño del contexto\n",
    "\n",
    "En este caso, como el modelo de lenguaje es por caracteres, todo un gran corpus\n",
    "de texto puede ser considerado un documento en sí mismo y el tamaño de contexto\n",
    "puede ser elegido con más libertad en comparación a un modelo de lenguaje tokenizado por palabras y dividido en documentos más acotados."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "id": "wumBNwdjJM3j"
   },
   "outputs": [],
   "source": [
    "# seleccionamos el tamaño de contexto\n",
    "max_context_size = 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "id": "m5FeTaGvbDbw"
   },
   "outputs": [],
   "source": [
    "# Usaremos las utilidades de procesamiento de textos y secuencias de Keras\n",
    "from tensorflow.keras.utils import pad_sequences # se utilizará para padding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "id": "573Cg5n7VhWw"
   },
   "outputs": [],
   "source": [
    "# en este caso el vocabulario es el conjunto único de caracteres que existe en todo el texto\n",
    "chars_vocab = set(texto)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "id": "VwTK6xgLJd8q"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "80"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# la longitud de vocabulario de caracteres es:\n",
    "len(chars_vocab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "id": "2W0AeQjXV1Ou"
   },
   "outputs": [],
   "source": [
    "# Construimos los dicionarios que asignan índices a caracteres y viceversa.\n",
    "# El diccionario `char2idx` servirá como tokenizador.\n",
    "char2idx = {k: v for v,k in enumerate(chars_vocab)}\n",
    "idx2char = {v: k for k,v in char2idx.items()}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "2oIUjVU0LB0r"
   },
   "source": [
    "###  Tokenizar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "id": "h07G3srdJppo"
   },
   "outputs": [],
   "source": [
    "# tokenizamos el texto completo\n",
    "tokenized_text = [char2idx[ch] for ch in texto]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "id": "PwGVSKOiJ5bj"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[52,\n",
       " 0,\n",
       " 73,\n",
       " 35,\n",
       " 53,\n",
       " 61,\n",
       " 63,\n",
       " 31,\n",
       " 22,\n",
       " 73,\n",
       " 75,\n",
       " 53,\n",
       " 5,\n",
       " 51,\n",
       " 66,\n",
       " 36,\n",
       " 73,\n",
       " 15,\n",
       " 19,\n",
       " 37,\n",
       " 5,\n",
       " 5,\n",
       " 22,\n",
       " 1,\n",
       " 20,\n",
       " 22,\n",
       " 46,\n",
       " 72,\n",
       " 73,\n",
       " 16,\n",
       " 37,\n",
       " 5,\n",
       " 36,\n",
       " 3,\n",
       " 36,\n",
       " 42,\n",
       " 37,\n",
       " 28,\n",
       " 1,\n",
       " 1,\n",
       " 11,\n",
       " 1,\n",
       " 1,\n",
       " 54,\n",
       " 8,\n",
       " 37,\n",
       " 6,\n",
       " 51,\n",
       " 22,\n",
       " 73,\n",
       " 36,\n",
       " 64,\n",
       " 58,\n",
       " 32,\n",
       " 73,\n",
       " 18,\n",
       " 11,\n",
       " 38,\n",
       " 4,\n",
       " 1,\n",
       " 8,\n",
       " 66,\n",
       " 51,\n",
       " 61,\n",
       " 0,\n",
       " 22,\n",
       " 29,\n",
       " 73,\n",
       " 52,\n",
       " 0,\n",
       " 73,\n",
       " 35,\n",
       " 53,\n",
       " 61,\n",
       " 63,\n",
       " 31,\n",
       " 22,\n",
       " 73,\n",
       " 75,\n",
       " 53,\n",
       " 5,\n",
       " 51,\n",
       " 66,\n",
       " 36,\n",
       " 73,\n",
       " 15,\n",
       " 19,\n",
       " 37,\n",
       " 5,\n",
       " 5,\n",
       " 22,\n",
       " 1,\n",
       " 10,\n",
       " 61,\n",
       " 51,\n",
       " 22,\n",
       " 5,\n",
       " 29,\n",
       " 73,\n",
       " 20,\n",
       " 22,\n",
       " 46,\n",
       " 72,\n",
       " 73,\n",
       " 16,\n",
       " 37,\n",
       " 5,\n",
       " 36,\n",
       " 3,\n",
       " 36,\n",
       " 42,\n",
       " 37,\n",
       " 28,\n",
       " 1,\n",
       " 52,\n",
       " 51,\n",
       " 19,\n",
       " 14,\n",
       " 61,\n",
       " 37,\n",
       " 51,\n",
       " 53,\n",
       " 46,\n",
       " 29,\n",
       " 73,\n",
       " 50,\n",
       " 22,\n",
       " 37,\n",
       " 46,\n",
       " 66,\n",
       " 53,\n",
       " 1,\n",
       " 52,\n",
       " 42,\n",
       " 19,\n",
       " 51,\n",
       " 22,\n",
       " 5,\n",
       " 29,\n",
       " 73,\n",
       " 52,\n",
       " 42,\n",
       " 61,\n",
       " 73,\n",
       " 25,\n",
       " 22,\n",
       " 30,\n",
       " 46,\n",
       " 69,\n",
       " 1,\n",
       " 15,\n",
       " 37,\n",
       " 63,\n",
       " 31,\n",
       " 53,\n",
       " 73,\n",
       " 42,\n",
       " 37,\n",
       " 73,\n",
       " 63,\n",
       " 5,\n",
       " 37,\n",
       " 53,\n",
       " 63,\n",
       " 19,\n",
       " 9,\n",
       " 36,\n",
       " 29,\n",
       " 73,\n",
       " 11,\n",
       " 40,\n",
       " 73,\n",
       " 42,\n",
       " 37,\n",
       " 73,\n",
       " 37,\n",
       " 36,\n",
       " 37,\n",
       " 5,\n",
       " 22,\n",
       " 73,\n",
       " 42,\n",
       " 37,\n",
       " 73,\n",
       " 47,\n",
       " 57,\n",
       " 11,\n",
       " 44,\n",
       " 1,\n",
       " 15,\n",
       " 37,\n",
       " 63,\n",
       " 31,\n",
       " 53,\n",
       " 73,\n",
       " 42,\n",
       " 37,\n",
       " 73,\n",
       " 58,\n",
       " 22,\n",
       " 42,\n",
       " 19,\n",
       " 26,\n",
       " 19,\n",
       " 63,\n",
       " 53,\n",
       " 63,\n",
       " 19,\n",
       " 9,\n",
       " 36,\n",
       " 29,\n",
       " 73,\n",
       " 11,\n",
       " 40,\n",
       " 73,\n",
       " 42,\n",
       " 37,\n",
       " 73,\n",
       " 37,\n",
       " 36,\n",
       " 37,\n",
       " 5,\n",
       " 22,\n",
       " 73,\n",
       " 42,\n",
       " 37,\n",
       " 73,\n",
       " 47,\n",
       " 57,\n",
       " 11,\n",
       " 44,\n",
       " 1,\n",
       " 52,\n",
       " 42,\n",
       " 19,\n",
       " 51,\n",
       " 53,\n",
       " 73,\n",
       " 51,\n",
       " 37,\n",
       " 6,\n",
       " 51,\n",
       " 22,\n",
       " 46,\n",
       " 32,\n",
       " 19,\n",
       " 36,\n",
       " 26,\n",
       " 22,\n",
       " 1,\n",
       " 75,\n",
       " 53,\n",
       " 19,\n",
       " 46,\n",
       " 22,\n",
       " 36,\n",
       " 73,\n",
       " 41,\n",
       " 53,\n",
       " 5,\n",
       " 5,\n",
       " 72,\n",
       " 37,\n",
       " 1,\n",
       " 63,\n",
       " 59,\n",
       " 73,\n",
       " 25,\n",
       " 53,\n",
       " 58,\n",
       " 53,\n",
       " 0,\n",
       " 27,\n",
       " 73,\n",
       " 18,\n",
       " 38,\n",
       " 1,\n",
       " 57,\n",
       " 4,\n",
       " 4,\n",
       " 40,\n",
       " 57,\n",
       " 73,\n",
       " 10,\n",
       " 0,\n",
       " 53,\n",
       " 69,\n",
       " 22,\n",
       " 5,\n",
       " 73,\n",
       " 49,\n",
       " 73,\n",
       " 75,\n",
       " 37,\n",
       " 36,\n",
       " 22,\n",
       " 5,\n",
       " 63,\n",
       " 53,\n",
       " 1,\n",
       " 67,\n",
       " 46,\n",
       " 0,\n",
       " 53,\n",
       " 46,\n",
       " 73,\n",
       " 12,\n",
       " 53,\n",
       " 0,\n",
       " 37,\n",
       " 53,\n",
       " 5,\n",
       " 37,\n",
       " 46,\n",
       " 1,\n",
       " 52,\n",
       " 46,\n",
       " 7,\n",
       " 53,\n",
       " 74,\n",
       " 53,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 47,\n",
       " 1,\n",
       " 1,\n",
       " 54,\n",
       " 67,\n",
       " 1,\n",
       " 10,\n",
       " 14,\n",
       " 61,\n",
       " 66,\n",
       " 73,\n",
       " 58,\n",
       " 37,\n",
       " 73,\n",
       " 7,\n",
       " 22,\n",
       " 36,\n",
       " 77,\n",
       " 22,\n",
       " 73,\n",
       " 53,\n",
       " 73,\n",
       " 63,\n",
       " 53,\n",
       " 36,\n",
       " 51,\n",
       " 53,\n",
       " 5,\n",
       " 1,\n",
       " 53,\n",
       " 0,\n",
       " 73,\n",
       " 63,\n",
       " 22,\n",
       " 58,\n",
       " 7,\n",
       " 3,\n",
       " 46,\n",
       " 73,\n",
       " 42,\n",
       " 37,\n",
       " 73,\n",
       " 0,\n",
       " 53,\n",
       " 73,\n",
       " 23,\n",
       " 19,\n",
       " 77,\n",
       " 45,\n",
       " 37,\n",
       " 0,\n",
       " 53,\n",
       " 27,\n",
       " 1,\n",
       " 14,\n",
       " 61,\n",
       " 37,\n",
       " 73,\n",
       " 37,\n",
       " 0,\n",
       " 73,\n",
       " 31,\n",
       " 22,\n",
       " 58,\n",
       " 30,\n",
       " 5,\n",
       " 37,\n",
       " 73,\n",
       " 14,\n",
       " 61,\n",
       " 37,\n",
       " 73,\n",
       " 0,\n",
       " 22,\n",
       " 73,\n",
       " 42,\n",
       " 37,\n",
       " 46,\n",
       " 23,\n",
       " 37,\n",
       " 0,\n",
       " 53,\n",
       " 1,\n",
       " 61,\n",
       " 36,\n",
       " 53,\n",
       " 73,\n",
       " 7,\n",
       " 37,\n",
       " 36,\n",
       " 53,\n",
       " 73,\n",
       " 37,\n",
       " 46,\n",
       " 51,\n",
       " 5,\n",
       " 22,\n",
       " 5,\n",
       " 42,\n",
       " 19,\n",
       " 36,\n",
       " 53,\n",
       " 5,\n",
       " 19,\n",
       " 53,\n",
       " 27,\n",
       " 1,\n",
       " 63,\n",
       " 22,\n",
       " 58,\n",
       " 22,\n",
       " 73,\n",
       " 0,\n",
       " 53,\n",
       " 73,\n",
       " 53,\n",
       " 23,\n",
       " 37,\n",
       " 73,\n",
       " 46,\n",
       " 22,\n",
       " 0,\n",
       " 19,\n",
       " 51,\n",
       " 53,\n",
       " 5,\n",
       " 19,\n",
       " 53,\n",
       " 1,\n",
       " 63,\n",
       " 22,\n",
       " 36,\n",
       " 73,\n",
       " 37,\n",
       " 0,\n",
       " 73,\n",
       " 63,\n",
       " 53,\n",
       " 36,\n",
       " 51,\n",
       " 53,\n",
       " 5,\n",
       " 73,\n",
       " 46,\n",
       " 37,\n",
       " 73,\n",
       " 63,\n",
       " 22,\n",
       " 36,\n",
       " 46,\n",
       " 61,\n",
       " 37,\n",
       " 0,\n",
       " 53,\n",
       " 32,\n",
       " 1,\n",
       " 50,\n",
       " 19,\n",
       " 42,\n",
       " 22,\n",
       " 73,\n",
       " 53,\n",
       " 73,\n",
       " 0,\n",
       " 22,\n",
       " 46,\n",
       " 73,\n",
       " 39,\n",
       " 53,\n",
       " 36,\n",
       " 51,\n",
       " 22,\n",
       " 46,\n",
       " 73,\n",
       " 42,\n",
       " 37,\n",
       " 0,\n",
       " 73,\n",
       " 41,\n",
       " 19,\n",
       " 37,\n",
       " 0,\n",
       " 22,\n",
       " 1,\n",
       " 14,\n",
       " 61,\n",
       " 37,\n",
       " 73,\n",
       " 53,\n",
       " 69,\n",
       " 61,\n",
       " 42,\n",
       " 37,\n",
       " 36,\n",
       " 73,\n",
       " 58,\n",
       " 19,\n",
       " 73,\n",
       " 7,\n",
       " 37,\n",
       " 36,\n",
       " 46,\n",
       " 53,\n",
       " 58,\n",
       " 19,\n",
       " 37,\n",
       " 36,\n",
       " 51,\n",
       " 22,\n",
       " 27,\n",
       " 1,\n",
       " 0,\n",
       " 37,\n",
       " 46,\n",
       " 73,\n",
       " 7,\n",
       " 19,\n",
       " 42,\n",
       " 22,\n",
       " 73,\n",
       " 37,\n",
       " 36,\n",
       " 73,\n",
       " 37,\n",
       " 46,\n",
       " 51,\n",
       " 37,\n",
       " 73,\n",
       " 58,\n",
       " 22,\n",
       " 58,\n",
       " 37,\n",
       " 36,\n",
       " 51,\n",
       " 22,\n",
       " 1,\n",
       " 14,\n",
       " 61,\n",
       " 37,\n",
       " 73,\n",
       " 23,\n",
       " 22,\n",
       " 69,\n",
       " 73,\n",
       " 53,\n",
       " 73,\n",
       " 63,\n",
       " 53,\n",
       " 36,\n",
       " 51,\n",
       " 53,\n",
       " 5,\n",
       " 73,\n",
       " 58,\n",
       " 19,\n",
       " 73,\n",
       " 31,\n",
       " 19,\n",
       " 46,\n",
       " 51,\n",
       " 22,\n",
       " 5,\n",
       " 19,\n",
       " 53,\n",
       " 1,\n",
       " 58,\n",
       " 37,\n",
       " 73,\n",
       " 5,\n",
       " 37,\n",
       " 26,\n",
       " 5,\n",
       " 37,\n",
       " 46,\n",
       " 14,\n",
       " 61,\n",
       " 37,\n",
       " 36,\n",
       " 73,\n",
       " 0,\n",
       " 53,\n",
       " 73,\n",
       " 58,\n",
       " 37,\n",
       " 58,\n",
       " 22,\n",
       " 5,\n",
       " 19,\n",
       " 53,\n",
       " 1,\n",
       " 69,\n",
       " 73,\n",
       " 53,\n",
       " 63,\n",
       " 0,\n",
       " 53,\n",
       " 5,\n",
       " 37,\n",
       " 36,\n",
       " 73,\n",
       " 58,\n",
       " 19,\n",
       " 73,\n",
       " 37,\n",
       " 36,\n",
       " 51,\n",
       " 37,\n",
       " 36,\n",
       " 42,\n",
       " 19,\n",
       " 58,\n",
       " 19,\n",
       " 37,\n",
       " 36,\n",
       " 51,\n",
       " 22,\n",
       " 32,\n",
       " 1,\n",
       " 13,\n",
       " 37,\n",
       " 36,\n",
       " 77,\n",
       " 53,\n",
       " 36,\n",
       " 73,\n",
       " 39,\n",
       " 53,\n",
       " 36,\n",
       " 51,\n",
       " 22,\n",
       " 46,\n",
       " 73,\n",
       " 58,\n",
       " 19,\n",
       " 0,\n",
       " 53,\n",
       " 77,\n",
       " 5,\n",
       " 22,\n",
       " 46,\n",
       " 22,\n",
       " 46,\n",
       " 27,\n",
       " 1,\n",
       " 23,\n",
       " 37,\n",
       " 36,\n",
       " 77,\n",
       " 53,\n",
       " 36,\n",
       " 73,\n",
       " 51,\n",
       " 22,\n",
       " 42,\n",
       " 22,\n",
       " 46,\n",
       " 73,\n",
       " 37,\n",
       " 36,\n",
       " 73,\n",
       " 58,\n",
       " 19,\n",
       " 73,\n",
       " 53,\n",
       " 69,\n",
       " 61,\n",
       " 42,\n",
       " 53,\n",
       " 27,\n",
       " 1,\n",
       " 14,\n",
       " 61,\n",
       " 37,\n",
       " 73,\n",
       " 0,\n",
       " 53,\n",
       " 73,\n",
       " 0,\n",
       " 37,\n",
       " 36,\n",
       " 77,\n",
       " 61,\n",
       " 53,\n",
       " 73,\n",
       " 46,\n",
       " 37,\n",
       " 73,\n",
       " 58,\n",
       " 37,\n",
       " 73,\n",
       " 53,\n",
       " 74,\n",
       " 61,\n",
       " 42,\n",
       " 53,\n",
       " 1,\n",
       " 69,\n",
       " 73,\n",
       " 46,\n",
       " 37,\n",
       " 73,\n",
       " 58,\n",
       " 37,\n",
       " 73,\n",
       " 51,\n",
       " 61,\n",
       " 5,\n",
       " 30,\n",
       " 53,\n",
       " 73,\n",
       " 0,\n",
       " 53,\n",
       " 73,\n",
       " 23,\n",
       " 19,\n",
       " 46,\n",
       " 51,\n",
       " 53,\n",
       " 34,\n",
       " 1,\n",
       " 7,\n",
       " 19,\n",
       " 42,\n",
       " 22,\n",
       " 73,\n",
       " 53,\n",
       " 73,\n",
       " 58,\n",
       " 19,\n",
       " 73,\n",
       " 33,\n",
       " 19,\n",
       " 22,\n",
       " 46,\n",
       " 73,\n",
       " 14,\n",
       " 61,\n",
       " 37,\n",
       " 73,\n",
       " 58,\n",
       " 37,\n",
       " 73,\n",
       " 53,\n",
       " 46,\n",
       " 19,\n",
       " 46,\n",
       " 51,\n",
       " 53,\n",
       " 1,\n",
       " 37,\n",
       " 36,\n",
       " 73,\n",
       " 61,\n",
       " 36,\n",
       " 53,\n",
       " 73,\n",
       " 22,\n",
       " 63,\n",
       " 53,\n",
       " 46,\n",
       " 19,\n",
       " 9,\n",
       " 36,\n",
       " 73,\n",
       " 51,\n",
       " 53,\n",
       " 36,\n",
       " 73,\n",
       " 5,\n",
       " 61,\n",
       " 42,\n",
       " 53,\n",
       " 32,\n",
       " 1,\n",
       " 70,\n",
       " 22,\n",
       " 73,\n",
       " 31,\n",
       " 37,\n",
       " 73,\n",
       " 23,\n",
       " 19,\n",
       " 46,\n",
       " 51,\n",
       " 22,\n",
       " 73,\n",
       " 58,\n",
       " 61,\n",
       " 63,\n",
       " 31,\n",
       " 22,\n",
       " 46,\n",
       " 73,\n",
       " 63,\n",
       " 53,\n",
       " 36,\n",
       " 51,\n",
       " 22,\n",
       " 5,\n",
       " 37,\n",
       " 46,\n",
       " 27,\n",
       " 1,\n",
       " 63,\n",
       " 22,\n",
       " 36,\n",
       " 73,\n",
       " 26,\n",
       " 53,\n",
       " 58,\n",
       " 53,\n",
       " 46,\n",
       " 73,\n",
       " 30,\n",
       " 19,\n",
       " 37,\n",
       " 36,\n",
       " 73,\n",
       " 22,\n",
       " 51,\n",
       " 37,\n",
       " 36,\n",
       " 19,\n",
       " 42,\n",
       " 53,\n",
       " 46,\n",
       " 27,\n",
       " 1,\n",
       " 69,\n",
       " 73,\n",
       " 14,\n",
       " 61,\n",
       " 37,\n",
       " 73,\n",
       " 42,\n",
       " 37,\n",
       " 46,\n",
       " 7,\n",
       " 61,\n",
       " 72,\n",
       " 46,\n",
       " 73,\n",
       " 42,\n",
       " 37,\n",
       " 73,\n",
       " 53,\n",
       " 0,\n",
       " 14,\n",
       " 61,\n",
       " 19,\n",
       " 5,\n",
       " 19,\n",
       " 42,\n",
       " 53,\n",
       " 46,\n",
       " 1,\n",
       " 36,\n",
       " 22,\n",
       " 73,\n",
       " 0,\n",
       " 53,\n",
       " 46,\n",
       " 73,\n",
       " 14,\n",
       " 61,\n",
       " 19,\n",
       " 37,\n",
       " 5,\n",
       " 37,\n",
       " 36,\n",
       " 73,\n",
       " 46,\n",
       " 61,\n",
       " 46,\n",
       " 51,\n",
       " 37,\n",
       " 36,\n",
       " 51,\n",
       " 53,\n",
       " 5,\n",
       " 7,\n",
       " 53,\n",
       " 5,\n",
       " 37,\n",
       " 63,\n",
       " 37,\n",
       " 73,\n",
       " 14,\n",
       " 61,\n",
       " 37,\n",
       " 73,\n",
       " 46,\n",
       " 19,\n",
       " 36,\n",
       " 73,\n",
       " 0,\n",
       " 53,\n",
       " 5,\n",
       " 77,\n",
       " 53,\n",
       " 5,\n",
       " 1,\n",
       " 46,\n",
       " 37,\n",
       " 73,\n",
       " 63,\n",
       " 53,\n",
       " 36,\n",
       " 46,\n",
       " 53,\n",
       " 5,\n",
       " 22,\n",
       " 36,\n",
       " 73,\n",
       " 37,\n",
       " 36,\n",
       " 73,\n",
       " 7,\n",
       " 53,\n",
       " 5,\n",
       " 51,\n",
       " 19,\n",
       " 42,\n",
       " 53,\n",
       " 46,\n",
       " 32,\n",
       " 1,\n",
       " 75,\n",
       " 53,\n",
       " 46,\n",
       " 73,\n",
       " 53,\n",
       " 36,\n",
       " 42,\n",
       " 37,\n",
       " 73,\n",
       " 22,\n",
       " 51,\n",
       " 5,\n",
       " 22,\n",
       " 73,\n",
       " 63,\n",
       " 5,\n",
       " 19,\n",
       " 22,\n",
       " 0,\n",
       " 0,\n",
       " 22,\n",
       " 73,\n",
       " 7,\n",
       " 53,\n",
       " 46,\n",
       " 53,\n",
       " 1,\n",
       " 75,\n",
       " 53,\n",
       " 5,\n",
       " 51,\n",
       " 66,\n",
       " 36,\n",
       " 73,\n",
       " 15,\n",
       " 19,\n",
       " 37,\n",
       " 5,\n",
       " 5,\n",
       " 22,\n",
       " 73,\n",
       " 31,\n",
       " 53,\n",
       " 73,\n",
       " 42,\n",
       " 37,\n",
       " 73,\n",
       " 7]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenized_text[:1000]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "pfpYcaypKcI9"
   },
   "source": [
    "### Organizando y estructurando el dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "id": "WSSmg9jtKP0T"
   },
   "outputs": [],
   "source": [
    "# separaremos el dataset entre entrenamiento y validación.\n",
    "# `p_val` será la proporción del corpus que se reservará para validación\n",
    "# `num_val` es la cantidad de secuencias de tamaño `max_context_size` que se usará en validación\n",
    "p_val = 0.1\n",
    "num_val = int(np.ceil(len(tokenized_text)*p_val/max_context_size))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "id": "b7dCpGrdKll0"
   },
   "outputs": [],
   "source": [
    "# separamos la porción de texto utilizada en entrenamiento de la de validación.\n",
    "train_text = tokenized_text[:-num_val*max_context_size]\n",
    "val_text = tokenized_text[-num_val*max_context_size:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "id": "NmxQdxl8LRCg"
   },
   "outputs": [],
   "source": [
    "tokenized_sentences_val = [val_text[init*max_context_size:init*(max_context_size+1)] for init in range(num_val)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "id": "_gyFT9koLqDm"
   },
   "outputs": [],
   "source": [
    "tokenized_sentences_train = [train_text[init:init+max_context_size] for init in range(len(train_text)-max_context_size+1)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "id": "oVNqmmLRodT0"
   },
   "outputs": [],
   "source": [
    "X = np.array(tokenized_sentences_train[:-1])\n",
    "y = np.array(tokenized_sentences_train[1:])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Vken7O4ETsAJ"
   },
   "source": [
    "Nótese que estamos estructurando el problema de aprendizaje como *many-to-many*:\n",
    "\n",
    "Entrada: secuencia de tokens [$x_0$, $x_1$, ..., $x_N$]\n",
    "\n",
    "Target: secuencia de tokens [$x_1$, $x_2$, ..., $x_{N+1}$]\n",
    "\n",
    "De manera que la red tiene que aprender que su salida deben ser los tokens desplazados en una posición y un nuevo token predicho (el N+1).\n",
    "\n",
    "La ventaja de estructurar el aprendizaje de esta manera es que para cada token de target se propaga una señal de gradiente por el grafo de cómputo recurrente, que es mejor que estructurar el problema como *many-to-one* en donde sólo una señal de gradiente se propaga."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "l3iPTx-UJl6r"
   },
   "source": [
    "En este punto tenemos en la variable `tokenized_sentences` los versos tokenizados. Vamos a quedarnos con un conjunto de validación que utilizaremos para medir la calidad de la generación de secuencias con la métrica de Perplejidad."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "id": "KFAyA4zCWE-5"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(54603, 100)"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "id": "qcKRl70HFTzG"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([52,  0, 73, 35, 53, 61, 63, 31, 22, 73])"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X[0,:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "id": "TVpLCKSZFXZO"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0, 73, 35, 53, 61, 63, 31, 22, 73, 75])"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y[0,:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "id": "wOFCR-KqbW1N"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "80"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vocab_size = len(chars_vocab)\n",
    "vocab_size"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "tnnjdAQ5UAEJ"
   },
   "source": [
    "# Definiendo el modelo SimpleRNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "id": "rkMCZvmhrQz4"
   },
   "outputs": [],
   "source": [
    "from keras.layers import Input, TimeDistributed, CategoryEncoding, SimpleRNN, Dense\n",
    "from keras.models import Model, Sequential"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "wgz7VKwTUbj6"
   },
   "source": [
    "El modelo que se propone como ejemplo consume los índices de los tokens y los transforma en vectores OHE (en este caso no entrenamos una capa de embedding para caracteres). Esa transformación se logra combinando las capas `CategoryEncoding` que transforma a índices a vectores OHE y `TimeDistributed` que aplica la capa a lo largo de la dimensión \"temporal\" de la secuencia."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "id": "Zd2OkfQYs2Q7"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Chelo\\anaconda3\\Lib\\site-packages\\keras\\src\\layers\\core\\wrapper.py:27: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"sequential\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ time_distributed                │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">80</span>)       │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">TimeDistributed</span>)               │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ simple_rnn (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">SimpleRNN</span>)          │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">200</span>)      │        <span style=\"color: #00af00; text-decoration-color: #00af00\">56,200</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">80</span>)       │        <span style=\"color: #00af00; text-decoration-color: #00af00\">16,080</span> │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ time_distributed                │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m80\u001b[0m)       │             \u001b[38;5;34m0\u001b[0m │\n",
       "│ (\u001b[38;5;33mTimeDistributed\u001b[0m)               │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ simple_rnn (\u001b[38;5;33mSimpleRNN\u001b[0m)          │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m200\u001b[0m)      │        \u001b[38;5;34m56,200\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense (\u001b[38;5;33mDense\u001b[0m)                   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m80\u001b[0m)       │        \u001b[38;5;34m16,080\u001b[0m │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">72,280</span> (282.34 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m72,280\u001b[0m (282.34 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">72,280</span> (282.34 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m72,280\u001b[0m (282.34 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "model = Sequential()\n",
    "\n",
    "model.add(TimeDistributed(CategoryEncoding(num_tokens=vocab_size, output_mode = \"one_hot\"),input_shape=(None,1)))\n",
    "model.add(SimpleRNN(200, return_sequences=True, dropout=0.1, recurrent_dropout=0.1 ))\n",
    "model.add(Dense(vocab_size, activation='softmax'))\n",
    "model.compile(loss='sparse_categorical_crossentropy', optimizer='rmsprop')\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "GmJWNyxQwfCE"
   },
   "source": [
    "\n",
    "### Definir el modelo"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "YWK3z85sQfUe"
   },
   "source": [
    "Dado que por el momento no hay implementaciones adecuadas de la perplejidad que puedan operar en tiempo de entrenamiento, armaremos un Callback *ad-hoc* que la calcule en cada epoch.\n",
    "\n",
    "**Nota**: un Callback es una rutina gatillada por algún evento, son muy útiles para relevar datos en diferentes momentos del desarrollo del modelo. En este caso queremos hacer un cálculo cada vez que termina una epoch de entrenamiento."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "id": "zUHX3r5JD-MG"
   },
   "outputs": [],
   "source": [
    "class PplCallback(keras.callbacks.Callback):\n",
    "\n",
    "    '''\n",
    "    Este callback es una solución ad-hoc para calcular al final de cada epoch de\n",
    "    entrenamiento la métrica de Perplejidad sobre un conjunto de datos de validación.\n",
    "    La perplejidad es una métrica cuantitativa para evaluar la calidad de la generación de secuencias.\n",
    "    Además implementa la finalización del entrenamiento (Early Stopping)\n",
    "    si la perplejidad no mejora después de `patience` epochs.\n",
    "    '''\n",
    "\n",
    "    def __init__(self, val_data, history_ppl,patience=5):\n",
    "      # El callback lo inicializamos con secuencias de validación sobre las cuales\n",
    "      # mediremos la perplejidad\n",
    "      self.val_data = val_data\n",
    "\n",
    "      self.target = []\n",
    "      self.padded = []\n",
    "\n",
    "      count = 0\n",
    "      self.info = []\n",
    "      self.min_score = np.inf\n",
    "      self.patience_counter = 0\n",
    "      self.patience = patience\n",
    "\n",
    "      # nos movemos en todas las secuencias de los datos de validación\n",
    "      for seq in self.val_data:\n",
    "\n",
    "        len_seq = len(seq)\n",
    "        # armamos todas las subsecuencias\n",
    "        subseq = [seq[:i] for i in range(1,len_seq)]\n",
    "        self.target.extend([seq[i] for i in range(1,len_seq)])\n",
    "\n",
    "        if len(subseq)!=0:\n",
    "\n",
    "          self.padded.append(pad_sequences(subseq, maxlen=max_context_size, padding='pre'))\n",
    "\n",
    "          self.info.append((count,count+len_seq))\n",
    "          count += len_seq\n",
    "\n",
    "      self.padded = np.vstack(self.padded)\n",
    "\n",
    "\n",
    "    def on_epoch_end(self, epoch, logs=None):\n",
    "\n",
    "        # en `scores` iremos guardando la perplejidad de cada secuencia\n",
    "        scores = []\n",
    "\n",
    "        predictions = self.model.predict(self.padded,verbose=0)\n",
    "\n",
    "        # para cada secuencia de validación\n",
    "        for start,end in self.info:\n",
    "\n",
    "          # en `probs` iremos guardando las probabilidades de los términos target\n",
    "          probs = [predictions[idx_seq,-1,idx_vocab] for idx_seq, idx_vocab in zip(range(start,end),self.target[start:end])]\n",
    "\n",
    "          # calculamos la perplejidad por medio de logaritmos\n",
    "          scores.append(np.exp(-np.sum(np.log(probs))/(end-start)))\n",
    "\n",
    "        # promediamos todos los scores e imprimimos el valor promedio\n",
    "        current_score = np.mean(scores)\n",
    "        history_ppl.append(current_score)\n",
    "        print(f'\\n mean perplexity: {current_score} \\n')\n",
    "\n",
    "        # chequeamos si tenemos que detener el entrenamiento\n",
    "        if current_score < self.min_score:\n",
    "          self.min_score = current_score\n",
    "          self.model.save(\"my_model.keras\")\n",
    "          print(\"Saved new model!\")\n",
    "          self.patience_counter = 0\n",
    "        else:\n",
    "          self.patience_counter += 1\n",
    "          if self.patience_counter == self.patience:\n",
    "            print(\"Stopping training...\")\n",
    "            self.model.stop_training = True\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "8HBZIwR0gruA"
   },
   "source": [
    "### Entrenamiento"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "id": "oQq1PHDkxDvN"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "\u001b[1m213/214\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 94ms/step - loss: 3.0229\n",
      " mean perplexity: 10.09808671061982 \n",
      "\n",
      "Saved new model!\n",
      "\u001b[1m214/214\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m31s\u001b[0m 117ms/step - loss: 3.0200\n",
      "Epoch 2/20\n",
      "\u001b[1m213/214\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 96ms/step - loss: 2.2931\n",
      " mean perplexity: 9.569748756413999 \n",
      "\n",
      "Saved new model!\n",
      "\u001b[1m214/214\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 98ms/step - loss: 2.2927\n",
      "Epoch 3/20\n",
      "\u001b[1m213/214\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 93ms/step - loss: 2.1701\n",
      " mean perplexity: 9.550679786616875 \n",
      "\n",
      "Saved new model!\n",
      "\u001b[1m214/214\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 95ms/step - loss: 2.1699\n",
      "Epoch 4/20\n",
      "\u001b[1m213/214\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 93ms/step - loss: 2.1005\n",
      " mean perplexity: 9.584416771421365 \n",
      "\n",
      "\u001b[1m214/214\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 95ms/step - loss: 2.1004\n",
      "Epoch 5/20\n",
      "\u001b[1m213/214\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 96ms/step - loss: 2.0414\n",
      " mean perplexity: 9.669680027325011 \n",
      "\n",
      "\u001b[1m214/214\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 98ms/step - loss: 2.0413\n",
      "Epoch 6/20\n",
      "\u001b[1m213/214\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 93ms/step - loss: 1.9898\n",
      " mean perplexity: 9.165449870367937 \n",
      "\n",
      "Saved new model!\n",
      "\u001b[1m214/214\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 97ms/step - loss: 1.9897\n",
      "Epoch 7/20\n",
      "\u001b[1m213/214\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 93ms/step - loss: 1.9467\n",
      " mean perplexity: 9.270883966459888 \n",
      "\n",
      "\u001b[1m214/214\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 95ms/step - loss: 1.9466\n",
      "Epoch 8/20\n",
      "\u001b[1m213/214\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 96ms/step - loss: 1.9069\n",
      " mean perplexity: 9.047131303183571 \n",
      "\n",
      "Saved new model!\n",
      "\u001b[1m214/214\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 98ms/step - loss: 1.9068\n",
      "Epoch 9/20\n",
      "\u001b[1m213/214\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 96ms/step - loss: 1.8778\n",
      " mean perplexity: 8.953063631793995 \n",
      "\n",
      "Saved new model!\n",
      "\u001b[1m214/214\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 99ms/step - loss: 1.8778\n",
      "Epoch 10/20\n",
      "\u001b[1m213/214\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 95ms/step - loss: 1.8496\n",
      " mean perplexity: 8.65993186857964 \n",
      "\n",
      "Saved new model!\n",
      "\u001b[1m214/214\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 98ms/step - loss: 1.8495\n",
      "Epoch 11/20\n",
      "\u001b[1m213/214\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 97ms/step - loss: 1.8232\n",
      " mean perplexity: 8.826674862592453 \n",
      "\n",
      "\u001b[1m214/214\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 100ms/step - loss: 1.8231\n",
      "Epoch 12/20\n",
      "\u001b[1m213/214\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 87ms/step - loss: 1.8006\n",
      " mean perplexity: 9.082711953416949 \n",
      "\n",
      "\u001b[1m214/214\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 90ms/step - loss: 1.8006\n",
      "Epoch 13/20\n",
      "\u001b[1m213/214\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 87ms/step - loss: 1.7817\n",
      " mean perplexity: 9.221471373440044 \n",
      "\n",
      "\u001b[1m214/214\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 89ms/step - loss: 1.7817\n",
      "Epoch 14/20\n",
      "\u001b[1m213/214\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 87ms/step - loss: 1.7641\n",
      " mean perplexity: 8.895374013097383 \n",
      "\n",
      "\u001b[1m214/214\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 89ms/step - loss: 1.7641\n",
      "Epoch 15/20\n",
      "\u001b[1m213/214\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 91ms/step - loss: 1.7489\n",
      " mean perplexity: 8.991006440962083 \n",
      "\n",
      "Stopping training...\n",
      "\u001b[1m214/214\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 94ms/step - loss: 1.7488\n"
     ]
    }
   ],
   "source": [
    "# fiteamos, nótese el agregado del callback con su inicialización. El batch_size lo podemos seleccionar a mano\n",
    "# en general, lo mejor es escoger el batch más grande posible que minimice el tiempo de cada época.\n",
    "# En la variable `history_ppl` se guardarán los valores de perplejidad para cada época.\n",
    "history_ppl = []\n",
    "hist = model.fit(X, y, epochs=20, callbacks=[PplCallback(tokenized_sentences_val,history_ppl)], batch_size=256)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "id": "K30JHB3Dv-mx"
   },
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# Entrenamiento\n",
    "epoch_count = range(1, len(history_ppl) + 1)\n",
    "sns.lineplot(x=epoch_count,  y=history_ppl)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "id": "Rhy5hZN38qfO"
   },
   "outputs": [],
   "source": [
    "# Cargamos el mejor modelo guardado del entrenamiento para hacer inferencia\n",
    "model = keras.models.load_model('my_model.keras')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "KN6Fg_BsxJe6"
   },
   "source": [
    "\n",
    "### Predicción del próximo caracter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {
    "id": "IBvKHFPmzpy2"
   },
   "outputs": [],
   "source": [
    "# Se puede usar gradio para probar el modelo\n",
    "# Gradio es una herramienta muy útil para crear interfaces para ensayar modelos\n",
    "# https://gradio.app/\n",
    "\n",
    "!pip install -q gradio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {
    "id": "HNyBykvhzs7-"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "* Running on local URL:  http://127.0.0.1:7860\n",
      "* To create a public link, set `share=True` in `launch()`.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div><iframe src=\"http://127.0.0.1:7860/\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1s/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step\n",
      "Keyboard interruption in main thread... closing server.\n"
     ]
    },
    {
     "data": {
      "text/plain": []
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import gradio as gr\n",
    "\n",
    "def model_response(human_text):\n",
    "\n",
    "    # Encodeamos\n",
    "    encoded = [char2idx[ch] for ch in human_text.lower() ]\n",
    "    # Si tienen distinto largo\n",
    "    encoded = pad_sequences([encoded], maxlen=max_context_size, padding='pre')\n",
    "\n",
    "    # Predicción softmax\n",
    "    y_hat = np.argmax(model.predict(encoded)[0,-1,:])\n",
    "\n",
    "\n",
    "    # Debemos buscar en el vocabulario el caracter\n",
    "    # que corresopnde al indice (y_hat) predicho por le modelo\n",
    "    out_word = ''\n",
    "    out_word = idx2char[y_hat]\n",
    "\n",
    "    # Agrego la palabra a la frase predicha\n",
    "    return human_text + out_word\n",
    "\n",
    "iface = gr.Interface(\n",
    "    fn=model_response,\n",
    "    inputs=[\"textbox\"],\n",
    "    outputs=\"text\")\n",
    "\n",
    "iface.launch(debug=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "mCeMWWupxN1-"
   },
   "source": [
    "### Generación de secuencias"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {
    "id": "bwbS_pfhxvB3"
   },
   "outputs": [],
   "source": [
    "def generate_seq(model, seed_text, max_length, n_words):\n",
    "    \"\"\"\n",
    "        Exec model sequence prediction\n",
    "\n",
    "        Args:\n",
    "            model (keras): melo entrenado\n",
    "            seed_text (string): texto de entrada (input_seq)\n",
    "            max_length (int): máxima longitud de la sequencia de entrada\n",
    "            n_words (int): números de caracteres a agregar a la sequencia de entrada\n",
    "        returns:\n",
    "            output_text (string): sentencia con las \"n_words\" agregadas\n",
    "    \"\"\"\n",
    "    output_text = seed_textod\n",
    "\t# generate a fixed number of words\n",
    "    for _ in range(n_words):\n",
    "\t\t# Encodeamos\n",
    "        encoded = [char2idx[ch] for ch in output_text.lower() ]\n",
    "\t\t# Si tienen distinto largo\n",
    "        encoded = pad_sequences([encoded], maxlen=max_length, padding='pre')\n",
    "\n",
    "\t\t# Predicción softmax\n",
    "        y_hat = np.argmax(model.predict(encoded,verbose=0)[0,-1,:])\n",
    "\t\t# Vamos concatenando las predicciones\n",
    "        out_word = ''\n",
    "\n",
    "        out_word = idx2char[y_hat]\n",
    "\n",
    "\t\t# Agrego las palabras a la frase predicha\n",
    "        output_text += out_word\n",
    "    return output_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {
    "id": "JoFqRC5pxzqS"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'la cosa anda tan fruncida\\ny al palo en el carreron\\nlos '"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input_text='la cosa anda tan fruncida'\n",
    "\n",
    "generate_seq(model, input_text, max_length=max_context_size, n_words=30)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "drJ6xn5qW1Hl"
   },
   "source": [
    "###  Beam search y muestreo aleatorio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {
    "id": "_vovn9XZW1Hl"
   },
   "outputs": [],
   "source": [
    "# funcionalidades para hacer encoding y decoding\n",
    "\n",
    "def encode(text,max_length=max_context_size):\n",
    "\n",
    "    encoded = [char2idx[ch] for ch in text]\n",
    "    encoded = pad_sequences([encoded], maxlen=max_length, padding='pre')\n",
    "\n",
    "    return encoded\n",
    "\n",
    "def decode(seq):\n",
    "    return ''.join([idx2char[ch] for ch in seq])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {
    "id": "I_lZiQwkW1Hl"
   },
   "outputs": [],
   "source": [
    "from scipy.special import softmax\n",
    "\n",
    "# función que selecciona candidatos para el beam search\n",
    "def select_candidates(pred,num_beams,vocab_size,history_probs,history_tokens,temp,mode):\n",
    "\n",
    "  # colectar todas las probabilidades para la siguiente búsqueda\n",
    "  pred_large = []\n",
    "\n",
    "  for idx,pp in enumerate(pred):\n",
    "    pred_large.extend(np.log(pp+1E-10)+history_probs[idx])\n",
    "\n",
    "  pred_large = np.array(pred_large)\n",
    "\n",
    "  # criterio de selección\n",
    "  if mode == 'det':\n",
    "    idx_select = np.argsort(pred_large)[::-1][:num_beams] # beam search determinista\n",
    "  elif mode == 'sto':\n",
    "    idx_select = np.random.choice(np.arange(pred_large.shape[0]), num_beams, p=softmax(pred_large/temp)) # beam search con muestreo aleatorio\n",
    "  else:\n",
    "    raise ValueError(f'Wrong selection mode. {mode} was given. det and sto are supported.')\n",
    "\n",
    "  # traducir a índices de token en el vocabulario\n",
    "  new_history_tokens = np.concatenate((np.array(history_tokens)[idx_select//vocab_size],\n",
    "                        np.array([idx_select%vocab_size]).T),\n",
    "                      axis=1)\n",
    "\n",
    "  # devolver el producto de las probabilidades (log) y la secuencia de tokens seleccionados\n",
    "  return pred_large[idx_select.astype(int)], new_history_tokens.astype(int)\n",
    "\n",
    "\n",
    "def beam_search(model,num_beams,num_words,input,temp=1,mode='det'):\n",
    "\n",
    "    # first iteration\n",
    "\n",
    "    # encode\n",
    "    encoded = encode(input)\n",
    "\n",
    "    # first prediction\n",
    "    y_hat = model.predict(encoded,verbose=0)[0,-1,:]\n",
    "\n",
    "    # get vocabulary size\n",
    "    vocab_size = y_hat.shape[0]\n",
    "\n",
    "    # initialize history\n",
    "    history_probs = [0]*num_beams\n",
    "    history_tokens = [encoded[0]]*num_beams\n",
    "\n",
    "    # select num_beams candidates\n",
    "    history_probs, history_tokens = select_candidates([y_hat],\n",
    "                                        num_beams,\n",
    "                                        vocab_size,\n",
    "                                        history_probs,\n",
    "                                        history_tokens,\n",
    "                                        temp,\n",
    "                                        mode)\n",
    "\n",
    "    # beam search loop\n",
    "    for i in range(num_words-1):\n",
    "\n",
    "      preds = []\n",
    "\n",
    "      for hist in history_tokens:\n",
    "\n",
    "        # actualizar secuencia de tokens\n",
    "        input_update = np.array([hist[i+1:]]).copy()\n",
    "\n",
    "        # predicción\n",
    "        y_hat = model.predict(input_update,verbose=0)[0,-1,:]\n",
    "\n",
    "        preds.append(y_hat)\n",
    "\n",
    "      history_probs, history_tokens = select_candidates(preds,\n",
    "                                                        num_beams,\n",
    "                                                        vocab_size,\n",
    "                                                        history_probs,\n",
    "                                                        history_tokens,\n",
    "                                                        temp,\n",
    "                                                        mode)\n",
    "\n",
    "    return history_tokens[:,-(len(input)+num_words):]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {
    "id": "GeLqAoOYW1Hm"
   },
   "outputs": [],
   "source": [
    "# predicción con beam search\n",
    "salidas = beam_search(model,num_beams=10,num_words=20,input=\"la cosa anda tan fruncida\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {
    "id": "P8HQoLhw-NYg"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0, 53, 73, 63, 22, 46, 53, 73, 53, 36, 42, 53, 73, 51, 53, 36, 73,\n",
       "       26,  5, 61, 36, 63, 19, 42, 53, 27,  1, 14, 61, 37, 73, 37,  0, 73,\n",
       "       77, 53, 61, 63, 31, 22, 73, 14, 61, 37, 73])"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "salidas[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {
    "id": "2S3_I3S1W1Hm"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'la cosa anda tan fruncida,\\nque el gaucho que '"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# veamos las salidas\n",
    "decode(salidas[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Probamos con greedy_search el modelo entrenado"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "def greedy_search(model, input_text, num_chars=100):\n",
    "    \"\"\"\n",
    "    Genera texto carácter por carácter usando búsqueda codiciosa.\n",
    "\n",
    "    Parámetros:\n",
    "    - model: modelo RNN ya entrenado\n",
    "    - input_text: texto semilla (str)\n",
    "    - num_chars: cuántos caracteres nuevos generar\n",
    "\n",
    "    Devuelve:\n",
    "    - texto generado completo (input + predicción)\n",
    "    \"\"\"\n",
    "\n",
    "    # Codificamos el texto inicial\n",
    "    encoded = encode(input_text)\n",
    "\n",
    "    # Lo convertimos a una lista de índices\n",
    "    generated = list(encoded[0])\n",
    "\n",
    "    for _ in range(num_chars):\n",
    "        # Extraemos la parte final de la secuencia\n",
    "        input_seq = np.array([generated[-max_context_size:]])  # Tamaño de contexto\n",
    "\n",
    "        # Predecimos el siguiente carácter\n",
    "        y_pred = model.predict(input_seq, verbose=0)[0, -1]\n",
    "\n",
    "        # Tomamos el índice del carácter con mayor probabilidad\n",
    "        next_char_idx = np.argmax(y_pred)\n",
    "\n",
    "        # Lo agregamos a la secuencia generada\n",
    "        generated.append(next_char_idx)\n",
    "\n",
    "    # Decodificamos a texto\n",
    "    return decode(generated[-(len(input_text) + num_chars):])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "la cosa anda tan fruncida\n",
      "y al palo en el carreron\n",
      "los palas de allí al como el gaucho se andaba\n",
      "y la acarra el corozón\n",
      "los palas de allí al como el gaucho se andaba\n",
      "y la acarra el corozón\n",
      "los palas de allí al como el gaucho \n"
     ]
    }
   ],
   "source": [
    "texto = greedy_search(model, input_text=\"la cosa anda tan fruncida\", num_chars=200)\n",
    "print(texto)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Q_LlqmtEW1Hn"
   },
   "source": [
    "# Ahora vamos a probar entrenando un modelo LSTM   return textos_generados\r\n",
    "    return textos_generados"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Definiendo el modelo LSTM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Chelo\\anaconda3\\Lib\\site-packages\\keras\\src\\layers\\core\\wrapper.py:27: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential_2\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"sequential_2\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ time_distributed_2              │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">80</span>)       │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">TimeDistributed</span>)               │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ lstm_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LSTM</span>)                   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">200</span>)      │       <span style=\"color: #00af00; text-decoration-color: #00af00\">224,800</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">80</span>)       │        <span style=\"color: #00af00; text-decoration-color: #00af00\">16,080</span> │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ time_distributed_2              │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m80\u001b[0m)       │             \u001b[38;5;34m0\u001b[0m │\n",
       "│ (\u001b[38;5;33mTimeDistributed\u001b[0m)               │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ lstm_1 (\u001b[38;5;33mLSTM\u001b[0m)                   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m200\u001b[0m)      │       \u001b[38;5;34m224,800\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_2 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m80\u001b[0m)       │        \u001b[38;5;34m16,080\u001b[0m │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">240,880</span> (940.94 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m240,880\u001b[0m (940.94 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">240,880</span> (940.94 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m240,880\u001b[0m (940.94 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "model = Sequential()\n",
    "\n",
    "model.add(TimeDistributed(CategoryEncoding(num_tokens=vocab_size, output_mode = \"one_hot\"),input_shape=(None,1)))\n",
    "model.add(LSTM(200, return_sequences=True, dropout=0.1, recurrent_dropout=0.1 ))\n",
    "model.add(Dense(vocab_size, activation='softmax'))\n",
    "model.compile(loss='sparse_categorical_crossentropy', optimizer='rmsprop')\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Entrenamiento"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "\u001b[1m214/214\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 336ms/step - loss: 3.2528\n",
      " mean perplexity: 16.21842494545471 \n",
      "\n",
      "Saved new model!\n",
      "\u001b[1m214/214\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m86s\u001b[0m 366ms/step - loss: 3.2520\n",
      "Epoch 2/20\n",
      "\u001b[1m214/214\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 291ms/step - loss: 2.7171\n",
      " mean perplexity: 11.702557303906415 \n",
      "\n",
      "Saved new model!\n",
      "\u001b[1m214/214\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m64s\u001b[0m 299ms/step - loss: 2.7167\n",
      "Epoch 3/20\n",
      "\u001b[1m214/214\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 288ms/step - loss: 2.4414\n",
      " mean perplexity: 9.92325551862784 \n",
      "\n",
      "Saved new model!\n",
      "\u001b[1m214/214\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m63s\u001b[0m 295ms/step - loss: 2.4412\n",
      "Epoch 4/20\n",
      "\u001b[1m214/214\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 294ms/step - loss: 2.3123\n",
      " mean perplexity: 9.342785349676625 \n",
      "\n",
      "Saved new model!\n",
      "\u001b[1m214/214\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m65s\u001b[0m 302ms/step - loss: 2.3122\n",
      "Epoch 5/20\n",
      "\u001b[1m214/214\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 290ms/step - loss: 2.2384\n",
      " mean perplexity: 8.896211271888173 \n",
      "\n",
      "Saved new model!\n",
      "\u001b[1m214/214\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m64s\u001b[0m 298ms/step - loss: 2.2384\n",
      "Epoch 6/20\n",
      "\u001b[1m214/214\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 301ms/step - loss: 2.1840\n",
      " mean perplexity: 8.69306465793871 \n",
      "\n",
      "Saved new model!\n",
      "\u001b[1m214/214\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m66s\u001b[0m 308ms/step - loss: 2.1840\n",
      "Epoch 7/20\n",
      "\u001b[1m214/214\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 300ms/step - loss: 2.1453\n",
      " mean perplexity: 8.469003266940435 \n",
      "\n",
      "Saved new model!\n",
      "\u001b[1m214/214\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m66s\u001b[0m 308ms/step - loss: 2.1453\n",
      "Epoch 8/20\n",
      "\u001b[1m214/214\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 297ms/step - loss: 2.1114\n",
      " mean perplexity: 8.305289306573231 \n",
      "\n",
      "Saved new model!\n",
      "\u001b[1m214/214\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m65s\u001b[0m 305ms/step - loss: 2.1114\n",
      "Epoch 9/20\n",
      "\u001b[1m214/214\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 307ms/step - loss: 2.0835\n",
      " mean perplexity: 8.447352902913627 \n",
      "\n",
      "\u001b[1m214/214\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m67s\u001b[0m 315ms/step - loss: 2.0834\n",
      "Epoch 10/20\n",
      "\u001b[1m214/214\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 314ms/step - loss: 2.0600\n",
      " mean perplexity: 8.21495171777092 \n",
      "\n",
      "Saved new model!\n",
      "\u001b[1m214/214\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m69s\u001b[0m 322ms/step - loss: 2.0599\n",
      "Epoch 11/20\n",
      "\u001b[1m214/214\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 313ms/step - loss: 2.0372\n",
      " mean perplexity: 8.113044457157496 \n",
      "\n",
      "Saved new model!\n",
      "\u001b[1m214/214\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m69s\u001b[0m 321ms/step - loss: 2.0372\n",
      "Epoch 12/20\n",
      "\u001b[1m214/214\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 324ms/step - loss: 2.0166\n",
      " mean perplexity: 8.113873577870736 \n",
      "\n",
      "\u001b[1m214/214\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m71s\u001b[0m 332ms/step - loss: 2.0165\n",
      "Epoch 13/20\n",
      "\u001b[1m214/214\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 311ms/step - loss: 1.9956\n",
      " mean perplexity: 8.214766436230134 \n",
      "\n",
      "\u001b[1m214/214\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m68s\u001b[0m 319ms/step - loss: 1.9956\n",
      "Epoch 14/20\n",
      "\u001b[1m214/214\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 307ms/step - loss: 1.9783\n",
      " mean perplexity: 7.992308005983486 \n",
      "\n",
      "Saved new model!\n",
      "\u001b[1m214/214\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m67s\u001b[0m 314ms/step - loss: 1.9783\n",
      "Epoch 15/20\n",
      "\u001b[1m214/214\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 311ms/step - loss: 1.9628\n",
      " mean perplexity: 8.058675463680798 \n",
      "\n",
      "\u001b[1m214/214\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m68s\u001b[0m 318ms/step - loss: 1.9628\n",
      "Epoch 16/20\n",
      "\u001b[1m214/214\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 311ms/step - loss: 1.9457\n",
      " mean perplexity: 8.0178295763792 \n",
      "\n",
      "\u001b[1m214/214\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m68s\u001b[0m 319ms/step - loss: 1.9457\n",
      "Epoch 17/20\n",
      "\u001b[1m214/214\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 316ms/step - loss: 1.9302\n",
      " mean perplexity: 7.845732750233709 \n",
      "\n",
      "Saved new model!\n",
      "\u001b[1m214/214\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m69s\u001b[0m 323ms/step - loss: 1.9302\n",
      "Epoch 18/20\n",
      "\u001b[1m214/214\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 311ms/step - loss: 1.9133\n",
      " mean perplexity: 7.91993848594119 \n",
      "\n",
      "\u001b[1m214/214\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m68s\u001b[0m 318ms/step - loss: 1.9133\n",
      "Epoch 19/20\n",
      "\u001b[1m214/214\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 305ms/step - loss: 1.8982\n",
      " mean perplexity: 8.209555394037995 \n",
      "\n",
      "\u001b[1m214/214\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m67s\u001b[0m 312ms/step - loss: 1.8982\n",
      "Epoch 20/20\n",
      "\u001b[1m214/214\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 311ms/step - loss: 1.8846\n",
      " mean perplexity: 8.06822811231196 \n",
      "\n",
      "\u001b[1m214/214\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m68s\u001b[0m 318ms/step - loss: 1.8846\n"
     ]
    }
   ],
   "source": [
    "# fiteamos, nótese el agregado del callback con su inicialización. El batch_size lo podemos seleccionar a mano\n",
    "# en general, lo mejor es escoger el batch más grande posible que minimice el tiempo de cada época.\n",
    "# En la variable `history_ppl` se guardarán los valores de perplejidad para cada época.\n",
    "history_ppl = []\n",
    "hist = model.fit(X, y, epochs=20, callbacks=[PplCallback(tokenized_sentences_val,history_ppl)], batch_size=256)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# Entrenamiento\n",
    "epoch_count = range(1, len(history_ppl) + 1)\n",
    "sns.lineplot(x=epoch_count,  y=history_ppl)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cargamos el mejor modelo guardado del entrenamiento para hacer inferencia\n",
    "model = keras.models.load_model('my_model.keras')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "* Running on local URL:  http://127.0.0.1:7860\n",
      "* To create a public link, set `share=True` in `launch()`.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div><iframe src=\"http://127.0.0.1:7860/\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2s/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 56ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 56ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 59ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 58ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 56ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 61ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 55ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 52ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 53ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 55ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 56ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 58ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 56ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 54ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 57ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 52ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 57ms/step\n",
      "Keyboard interruption in main thread... closing server.\n"
     ]
    },
    {
     "data": {
      "text/plain": []
     },
     "execution_count": 119,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import gradio as gr\n",
    "\n",
    "def model_response(human_text):\n",
    "\n",
    "    # Encodeamos\n",
    "    encoded = [char2idx[ch] for ch in human_text.lower() ]\n",
    "    # Si tienen distinto largo\n",
    "    encoded = pad_sequences([encoded], maxlen=max_context_size, padding='pre')\n",
    "\n",
    "    # Predicción softmax\n",
    "    y_hat = np.argmax(model.predict(encoded)[0,-1,:])\n",
    "\n",
    "\n",
    "    # Debemos buscar en el vocabulario el caracter\n",
    "    # que corresopnde al indice (y_hat) predicho por le modelo\n",
    "    out_word = ''\n",
    "    out_word = idx2char[y_hat]\n",
    "\n",
    "    # Agrego la palabra a la frase predicha\n",
    "    return human_text + out_word\n",
    "\n",
    "iface = gr.Interface(\n",
    "    fn=model_response,\n",
    "    inputs=[\"textbox\"],\n",
    "    outputs=\"text\")\n",
    "\n",
    "iface.launch(debug=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [],
   "source": [
    "# predicción con beam search\n",
    "salidas = beam_search(model,num_beams=10,num_words=20,input=\"la cosa anda tan fruncida\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0, 53, 73, 63, 22, 46, 53, 73, 53, 36, 42, 53, 73, 51, 53, 36, 73,\n",
       "       26,  5, 61, 36, 63, 19, 42, 53,  1, 14, 61, 37, 73, 37,  0, 73, 77,\n",
       "       53, 61, 63, 31, 22, 73, 14, 61, 37, 73, 37])"
      ]
     },
     "execution_count": 125,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "salidas[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'la cosa anda tan fruncida\\nque el gaucho que e'"
      ]
     },
     "execution_count": 126,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# veamos las salidas\n",
    "decode(salidas[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Conclusión \n",
    "\n",
    "En esta notebook se desarrolló un proyecto completo de **modelo de lenguaje a nivel de caracteres** aplicado a un corpus literario (el *Martín Fierro*).\n",
    "\n",
    "---\n",
    "\n",
    "### Preprocesamiento y Tokenización\n",
    "\n",
    "- Se trabajó con texto en bruto, convirtiéndolo a minúsculas y eliminando símbolos innecesarios.\n",
    "- Se definió un vocabulario de caracteres únicos (`char2idx`, `idx2char`) para codificar y decodificar texto.\n",
    "- Se utilizaron técnicas como `pad_sequences` y `encode/decode` para preparar los datos como secuencias de entrada para la red.\n",
    "\n",
    "---\n",
    "\n",
    "### Arquitecturas de Modelo\n",
    "\n",
    "- Se entrenaron dos variantes de redes neuronales recurrentes:\n",
    "  1. **SimpleRNN**\n",
    "  2. **LSTM**\n",
    "\n",
    "- Ambos modelos fueron entrenados para predecir el **siguiente carácter** en una secuencia dada.\n",
    "\n",
    "---\n",
    "\n",
    "### Evaluación con Perplejidad\n",
    "\n",
    "- Se implementó un `Callback` para calcular la **perplejidad** sobre un conjunto de validación al final de cada época.\n",
    "- Esta métrica permitió monitorear la calidad del modelo durante el entrenamiento y aplicar early stopping.\n",
    "\n",
    "---\n",
    "\n",
    "### Generación de Texto\n",
    "\n",
    "- Se implementaron dos estrategias para generar texto:\n",
    "  - **Greedy Search**: toma siempre el carácter con mayor probabilidad.\n",
    "  - **Beam Search**: mantiene múltiples trayectorias posibles para encontrar secuencias más coherentes.\n",
    "\n",
    "- También se incorporó la **temperatura** en la versión estocástica para controlar la aleatoriedad en la generación.\n",
    "\n",
    "---\n",
    "\n",
    "### Conclusión final\n",
    "\n",
    "> - Se observó que el modelo basado en **LSTM ofreció mejores resultados** en términos de **coherencia textual y menor perplejidad**. Las secuencias generadas fueron más fluidas, pero aun asi no fueron del todo exactos o esperados, probablemente falta hacer un mejor ajuste de los parametros de los modelos o bien hacer un pre tratamiento del texto diferente.\n",
    "> - Finalmente, se uso el Martín Fierro, una de las obras más representativas de la literatura gauchesca argentina. Este libro no solo ofrece riqueza poética y estilística, sino que además contiene numerosas expresiones del lunfardo y habla popular rioplatense, lo cual representa un desafío interesante para el modelado de lenguaje natural.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "T4",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
