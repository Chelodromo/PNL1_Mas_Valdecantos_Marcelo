{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "sZd5yLnnHOK0"
   },
   "source": [
    "<img src=\"https://github.com/hernancontigiani/ceia_memorias_especializacion/raw/master/Figures/logoFIUBA.jpg\" width=\"500\" align=\"center\">\n",
    "\n",
    "\n",
    "# Procesamiento de lenguaje natural\n",
    "## Custom embedddings con Gensim\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "vA7nqkumo9z9"
   },
   "source": [
    "### Objetivo\n",
    "El objetivo es utilizar documentos / corpus para crear embeddings de palabras basado en ese contexto. Se utilizará canciones de bandas para generar los embeddings, es decir, que los vectores tendrán la forma en función de como esa banda haya utilizado las palabras en sus canciones."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Alumno"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Crear sus propios vectores con Gensim basado en lo visto en clase con otro dataset.\n",
    "- Probar términos de interés y explicar similitudes en el espacio de embeddings (sacar conclusiones entre palabras similitudes y diferencias).\n",
    "- Graficarlos.\n",
    "- Obtener conclusiones."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "id": "lFToQs5FK5uZ",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "try:\n",
    "    import pandas as pd\n",
    "    import matplotlib.pyplot as plt\n",
    "    import seaborn as sns\n",
    "    import multiprocessing\n",
    "    from gensim.models import Word2Vec\n",
    "except Exception as e:\n",
    "    print(\"Error al importar:\", e)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "g07zJxG7H9vG"
   },
   "source": [
    "### Datos\n",
    "Utilizaremos como dataset el libro \"Martin Fierro\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {
    "id": "l7z4CSBfpR3X"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['el', 'gaucho', 'martín', 'fierro']\n",
      "['josé', 'hernández']\n",
      "[]\n",
      "['1']\n",
      "[]\n",
      "[]\n",
      "['texto', 'núm', '4187']\n",
      "['título', 'el', 'gaucho', 'martín', 'fierro']\n",
      "['autor', 'josé', 'hernández']\n",
      "['etiquetas', 'poesía']\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from tensorflow.keras.preprocessing.text import text_to_word_sequence\n",
    "\n",
    "# Leer el libro archivo línea por línea contenido en el archivo martin_fierro.txt\n",
    "with open('martin_fierro.txt', 'r', encoding='utf-8') as f:\n",
    "    lines = f.read().splitlines()\n",
    "\n",
    "# Convertir a DataFrame\n",
    "df = pd.DataFrame(lines, columns=['historia'])\n",
    "\n",
    "# Tokenizar cada línea\n",
    "sentence_tokens = []\n",
    "for _, row in df.iterrows():\n",
    "    sentence_tokens.append(text_to_word_sequence(row['historia']))\n",
    "\n",
    "# Mostrar algunos tokens\n",
    "for tokens in sentence_tokens[:10]:\n",
    "    print(tokens)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {
    "id": "ticoqYD1Z3I7"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>historia</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>El Gaucho Martín Fierro</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>José Hernández</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                  historia\n",
       "0  El Gaucho Martín Fierro\n",
       "1           José Hernández\n",
       "2                         \n",
       "3                        1\n",
       "4                         "
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "with open('martin_fierro.txt', 'r', encoding='utf-8') as f:\n",
    "    lines = f.read().splitlines()\n",
    "\n",
    "\n",
    "df = pd.DataFrame(lines, columns=['historia'])\n",
    "df.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {
    "id": "LEpKubK9XzXN"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cantidad de documentos: 2449\n"
     ]
    }
   ],
   "source": [
    "print(\"Cantidad de documentos:\", df.shape[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ab94qaFlrA1G"
   },
   "source": [
    "### 1 - Preprocesamiento"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {
    "id": "rIsmMWmjrDHd"
   },
   "outputs": [],
   "source": [
    "from tensorflow.keras.preprocessing.text import text_to_word_sequence\n",
    "\n",
    "sentence_tokens = []\n",
    "\n",
    "for _, row in df.iterrows():\n",
    "    sentence_tokens.append(text_to_word_sequence(row.iloc[0]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {
    "id": "CHepi_DGrbhq"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['el', 'gaucho', 'martín', 'fierro'], ['josé', 'hernández']]"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Demos un vistazo\n",
    "sentence_tokens[:2]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "BaXV6nlHr5Aa"
   },
   "source": [
    "### 2 - Crear los vectores (word2vec)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {
    "id": "OSb0v7h8r7hK"
   },
   "outputs": [],
   "source": [
    "from gensim.models.callbacks import CallbackAny2Vec\n",
    "# Durante el entrenamiento gensim por defecto no informa el \"loss\" en cada época\n",
    "# Sobrecargamos el callback para poder tener esta información\n",
    "class callback(CallbackAny2Vec):\n",
    "    \"\"\"\n",
    "    Callback to print loss after each epoch\n",
    "    \"\"\"\n",
    "    def __init__(self):\n",
    "        self.epoch = 0\n",
    "\n",
    "    def on_epoch_end(self, model):\n",
    "        loss = model.get_latest_training_loss()\n",
    "        if self.epoch == 0:\n",
    "            print('Loss after epoch {}: {}'.format(self.epoch, loss))\n",
    "        else:\n",
    "            print('Loss after epoch {}: {}'.format(self.epoch, loss- self.loss_previous_step))\n",
    "        self.epoch += 1\n",
    "        self.loss_previous_step = loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {
    "id": "i0wnDdv9sJ47"
   },
   "outputs": [],
   "source": [
    "# Crearmos el modelo generador de vectores\n",
    "# En este caso utilizaremos la estructura modelo Skipgram\n",
    "w2v_model = Word2Vec(min_count=3,    # frecuencia mínima de palabra para incluirla en el vocabulario\n",
    "                     window=2,       # cant de palabras antes y desp de la predicha\n",
    "                     vector_size=300,       # dimensionalidad de los vectores \n",
    "                     negative=20,    # cantidad de negative samples... 0 es no se usa\n",
    "                     workers=1,      # si tienen más cores pueden cambiar este valor\n",
    "                     sg=1)           # modelo 0:CBOW  1:skipgram"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {
    "id": "5lTt8wErsf17"
   },
   "outputs": [],
   "source": [
    "# Obtener el vocabulario con los tokens\n",
    "w2v_model.build_vocab(sentence_tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {
    "id": "TNc9qt4os5AT"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cantidad de docs en el corpus: 2449\n"
     ]
    }
   ],
   "source": [
    "# Cantidad de filas/docs encontradas en el corpus\n",
    "print(\"Cantidad de docs en el corpus:\", w2v_model.corpus_count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {
    "id": "idw9cHF3tSMl"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cantidad de words distintas en el corpus: 557\n"
     ]
    }
   ],
   "source": [
    "# Cantidad de words encontradas en el corpus\n",
    "print(\"Cantidad de words distintas en el corpus:\", len(w2v_model.wv.index_to_key))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "fC9mZ8DPk-UC"
   },
   "source": [
    "### 3 - Entrenar embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {
    "id": "QSp-x0PAsq56"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss after epoch 0: 89008.3671875\n",
      "Loss after epoch 1: 39834.140625\n",
      "Loss after epoch 2: 30790.8984375\n",
      "Loss after epoch 3: 28836.046875\n",
      "Loss after epoch 4: 28303.34375\n",
      "Loss after epoch 5: 28390.4375\n",
      "Loss after epoch 6: 27790.828125\n",
      "Loss after epoch 7: 27644.5\n",
      "Loss after epoch 8: 28414.3125\n",
      "Loss after epoch 9: 28205.78125\n",
      "Loss after epoch 10: 27970.625\n",
      "Loss after epoch 11: 27716.875\n",
      "Loss after epoch 12: 27839.125\n",
      "Loss after epoch 13: 28404.09375\n",
      "Loss after epoch 14: 27645.71875\n",
      "Loss after epoch 15: 27883.28125\n",
      "Loss after epoch 16: 28609.4375\n",
      "Loss after epoch 17: 28383.1875\n",
      "Loss after epoch 18: 29201.25\n",
      "Loss after epoch 19: 27680.0\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(94709, 225780)"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Entrenamos el modelo generador de vectores\n",
    "# Utilizamos nuestro callback\n",
    "w2v_model.train(sentence_tokens,\n",
    "                 total_examples=w2v_model.corpus_count,\n",
    "                 epochs=20,\n",
    "                 compute_loss = True,\n",
    "                 callbacks=[callback()]\n",
    "                 )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ddT9NVuNlCAe"
   },
   "source": [
    "### 4 - Ensayar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {
    "id": "6cHN9xGLuPEm"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('desgraciao', 0.999029815196991),\n",
       " ('hace', 0.9989508390426636),\n",
       " ('eso', 0.9989194273948669),\n",
       " ('juerte', 0.9989127516746521),\n",
       " ('ese', 0.9989070892333984),\n",
       " ('padecer', 0.9989000558853149),\n",
       " ('gato', 0.9988833665847778),\n",
       " ('aguanta', 0.9988819360733032),\n",
       " ('parece', 0.9988793134689331),\n",
       " ('arriba', 0.998876690864563)]"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Palabras que MÁS se relacionan con...:\n",
    "w2v_model.wv.most_similar(positive=[\"el\"], topn=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {
    "id": "47HiU5gdkdMq"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('vez', -0.9896597266197205),\n",
       " ('tal', -0.9900179505348206),\n",
       " ('he', -0.99434494972229),\n",
       " ('visto', -0.9965164065361023),\n",
       " ('o', -0.9972394108772278),\n",
       " ('esa', -0.9972704648971558),\n",
       " ('no', -0.9977584481239319),\n",
       " ('qué', -0.9978582262992859),\n",
       " ('mesmo', -0.9978677034378052),\n",
       " ('hay', -0.9979145526885986)]"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Palabras que MENOS se relacionan con...:\n",
    "w2v_model.wv.most_similar(negative=[\"cantar\"], topn=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {
    "id": "DT4Rvno2mD65"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('digo', 0.9994636178016663),\n",
       " ('dentra', 0.9994292855262756),\n",
       " ('redomón', 0.9994131326675415),\n",
       " ('lomo', 0.9994101524353027),\n",
       " ('duro', 0.9994089007377625),\n",
       " ('güelta', 0.9994075894355774),\n",
       " ('pingo', 0.9994034171104431),\n",
       " ('negro', 0.9993978142738342),\n",
       " ('bagual', 0.9993978142738342),\n",
       " ('moro', 0.9993952512741089)]"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Palabras que MÁS se relacionan con...:\n",
    "w2v_model.wv.most_similar(positive=[\"ande\"], topn=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {
    "id": "XPLDPgzBmQXt"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('andan', 0.9995988607406616),\n",
       " ('lomo', 0.9995643496513367),\n",
       " ('tres', 0.9995617866516113),\n",
       " ('atrás', 0.9995545148849487),\n",
       " ('sargento', 0.9995543360710144)]"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Palabras que MÁS se relacionan con...:\n",
    "w2v_model.wv.most_similar(positive=[\"padre\"], topn=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {
    "id": "L_UvHPMMklOr"
   },
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "\"Key 'bandido' not present in vocabulary\"",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[78], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m# Ensayar con una palabra que no está en el vocabulario: esta palabra da error porque no esta en el dioccionario\u001b[39;00m\n\u001b[1;32m----> 2\u001b[0m \u001b[43mw2v_model\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mwv\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmost_similar\u001b[49m\u001b[43m(\u001b[49m\u001b[43mnegative\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mbandido\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\nlp-env\\lib\\site-packages\\gensim\\models\\keyedvectors.py:841\u001b[0m, in \u001b[0;36mKeyedVectors.most_similar\u001b[1;34m(self, positive, negative, topn, clip_start, clip_end, restrict_vocab, indexer)\u001b[0m\n\u001b[0;32m    838\u001b[0m         weight[idx] \u001b[38;5;241m=\u001b[39m item[\u001b[38;5;241m1\u001b[39m]\n\u001b[0;32m    840\u001b[0m \u001b[38;5;66;03m# compute the weighted average of all keys\u001b[39;00m\n\u001b[1;32m--> 841\u001b[0m mean \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_mean_vector\u001b[49m\u001b[43m(\u001b[49m\u001b[43mkeys\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mweight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpre_normalize\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpost_normalize\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mignore_missing\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[0;32m    842\u001b[0m all_keys \u001b[38;5;241m=\u001b[39m [\n\u001b[0;32m    843\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mget_index(key) \u001b[38;5;28;01mfor\u001b[39;00m key \u001b[38;5;129;01min\u001b[39;00m keys \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(key, _KEY_TYPES) \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhas_index_for(key)\n\u001b[0;32m    844\u001b[0m ]\n\u001b[0;32m    846\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m indexer \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(topn, \u001b[38;5;28mint\u001b[39m):\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\nlp-env\\lib\\site-packages\\gensim\\models\\keyedvectors.py:518\u001b[0m, in \u001b[0;36mKeyedVectors.get_mean_vector\u001b[1;34m(self, keys, weights, pre_normalize, post_normalize, ignore_missing)\u001b[0m\n\u001b[0;32m    516\u001b[0m         total_weight \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;28mabs\u001b[39m(weights[idx])\n\u001b[0;32m    517\u001b[0m     \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m ignore_missing:\n\u001b[1;32m--> 518\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mKey \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mkey\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m not present in vocabulary\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m    520\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m total_weight \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[0;32m    521\u001b[0m     mean \u001b[38;5;241m=\u001b[39m mean \u001b[38;5;241m/\u001b[39m total_weight\n",
      "\u001b[1;31mKeyError\u001b[0m: \"Key 'bandido' not present in vocabulary\""
     ]
    }
   ],
   "source": [
    "# Ensayar con una palabra que no está en el vocabulario: esta palabra da error porque no esta en el dioccionario\n",
    "w2v_model.wv.most_similar(negative=[\"bandido\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-0.00050781  0.2085369  -0.06500391  0.05736004 -0.00975889 -0.17992401\n",
      "  0.17077117  0.3129725  -0.00903545 -0.04222796  0.0275842  -0.10434504\n",
      " -0.08883115  0.05350181 -0.04573907 -0.10932864  0.08587694 -0.01221502\n",
      "  0.09318512 -0.01396328 -0.03025087 -0.04882079  0.10858749  0.03946175\n",
      "  0.08637434 -0.00161521 -0.140606    0.03199051 -0.16930047 -0.18132226\n",
      "  0.09581241 -0.16078734  0.0455488   0.02948486 -0.03675834  0.00842973\n",
      "  0.12354623 -0.18974361 -0.02900615 -0.00854821 -0.02140403 -0.0380908\n",
      "  0.06241261 -0.03704563 -0.0281008   0.08867034  0.01622634 -0.08564964\n",
      " -0.01358147  0.09397678  0.00062217  0.03433939 -0.11237222  0.09785821\n",
      " -0.05706544  0.05991004  0.12803021  0.02283803  0.03350443 -0.05834982\n",
      " -0.04172467 -0.02563581 -0.01392855  0.02155487 -0.03369389  0.06768615\n",
      "  0.08464661 -0.01224829 -0.06556129 -0.00744201  0.03633333 -0.02451801\n",
      "  0.11885854 -0.0550122   0.08493529  0.07457112 -0.10137311  0.02181086\n",
      " -0.16268167  0.10109476 -0.11183537 -0.06784387 -0.01018817  0.22618972\n",
      "  0.0456112  -0.00211796 -0.07524733 -0.05824442  0.09397416  0.00917356\n",
      "  0.12699488 -0.06302842  0.04166155  0.0657024   0.10004106  0.07413415\n",
      "  0.05816761  0.0228088  -0.00481138 -0.03498773 -0.09917219  0.00963407\n",
      "  0.09012447  0.04965908  0.02001424 -0.19830574 -0.07364166  0.03103573\n",
      " -0.02903438 -0.01032774 -0.12489402 -0.01156362  0.03831137  0.07816394\n",
      "  0.15833218  0.08020452  0.00683067  0.09779888  0.16254133 -0.15579693\n",
      "  0.09041563  0.12752049  0.03626091 -0.09345907 -0.03649476  0.1218743\n",
      "  0.01208775 -0.09452888 -0.00647584  0.14071348  0.01657809  0.03059486\n",
      "  0.05835076 -0.21206641 -0.06372395  0.1108705   0.01579943 -0.14466959\n",
      " -0.1195074  -0.04552372 -0.03368225 -0.1372863  -0.03643016 -0.03977079\n",
      "  0.10741532 -0.04819505 -0.24065286 -0.03487508  0.10473016 -0.13142687\n",
      "  0.08007881 -0.26936725 -0.04330554 -0.06489655  0.05175591  0.11674819\n",
      " -0.14628537 -0.02241066 -0.01877373  0.10037088 -0.00314573  0.13692734\n",
      " -0.11200292  0.18266574  0.0024515   0.05059583 -0.08040179  0.01357405\n",
      "  0.05712457  0.26617032 -0.07203124  0.01913447 -0.01146992  0.0413133\n",
      " -0.00403037  0.06319571 -0.10332562 -0.143243    0.02590938 -0.00651337\n",
      " -0.04724636  0.00536292 -0.1636953   0.02890442 -0.10695961  0.16053212\n",
      "  0.14284965  0.03929736  0.06375747 -0.2132736   0.01389628 -0.01856147\n",
      " -0.16901906  0.11176106  0.06373772 -0.13499585  0.01588968 -0.09328835\n",
      " -0.08238684 -0.00759669 -0.24244505 -0.04196253  0.01720242 -0.09608885\n",
      "  0.05257338 -0.10365134  0.01046683  0.04192702  0.01010982  0.02439633\n",
      "  0.08546644 -0.09017226 -0.01518288  0.00331442  0.07756814 -0.1583034\n",
      " -0.07758089 -0.23568697 -0.23066455 -0.13398351  0.05305818  0.02654511\n",
      " -0.07732619 -0.11465681 -0.00276642 -0.09569846  0.05095534 -0.09358923\n",
      " -0.07240029  0.07835545  0.06574256 -0.05625158 -0.08863753 -0.04046479\n",
      " -0.1164247   0.03863489  0.03881818 -0.0129529  -0.03294882 -0.18411714\n",
      "  0.02135634 -0.0684287   0.01434321 -0.03110009  0.06022948 -0.18737978\n",
      "  0.04543882  0.03295051 -0.00790898  0.13674359  0.05053165 -0.03924111\n",
      "  0.0735833   0.05012207 -0.18152963 -0.15246302  0.21631129  0.09663314\n",
      " -0.18383072 -0.02280465  0.10145956  0.06536908  0.18506977 -0.11445549\n",
      " -0.23280303  0.03465971  0.17450996  0.05393888 -0.09978042  0.03206749\n",
      " -0.05487538  0.05342951 -0.0196283  -0.03749907  0.17101344  0.03483228\n",
      "  0.20773333  0.04368944 -0.19442214 -0.0067882   0.11024306 -0.01393442\n",
      " -0.12417299  0.05100559 -0.01413685 -0.02218818 -0.08201049  0.11725333\n",
      " -0.01919238  0.14590591  0.17399552  0.21451522  0.1061317  -0.02378073\n",
      "  0.1659266   0.27036825  0.09503715 -0.07890348  0.07034513 -0.12620232]\n"
     ]
    }
   ],
   "source": [
    "# el método `get_vector` permite obtener los vectores:\n",
    "vector_cantar = w2v_model.wv.get_vector(\"cantar\")\n",
    "print(vector_cantar)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('cantar', 0.9999999403953552),\n",
       " ('güelta', 0.9993950128555298),\n",
       " ('puse', 0.9993795156478882),\n",
       " ('camino', 0.9993779063224792),\n",
       " ('hago', 0.9993709921836853),\n",
       " ('servir', 0.9993592500686646),\n",
       " ('gritos', 0.9993585348129272),\n",
       " ('meses', 0.9993576407432556),\n",
       " ('destino', 0.9993570446968079),\n",
       " ('trabajar', 0.9993553161621094)]"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# el método `most_similar` también permite comparar a partir de vectores\n",
    "w2v_model.wv.most_similar(vector_cantar)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "_g8UVWe6lFmh"
   },
   "source": [
    "### 5 - Visualizar agrupación de vectores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {
    "id": "pDxEVXAivjr9"
   },
   "outputs": [],
   "source": [
    "from sklearn.decomposition import IncrementalPCA    \n",
    "from sklearn.manifold import TSNE                   \n",
    "import numpy as np                                  \n",
    "\n",
    "def reduce_dimensions(model, num_dimensions = 2 ):\n",
    "     \n",
    "    vectors = np.asarray(model.wv.vectors)\n",
    "    labels = np.asarray(model.wv.index_to_key)  \n",
    "\n",
    "    tsne = TSNE(n_components=num_dimensions, random_state=0)\n",
    "    vectors = tsne.fit_transform(vectors)\n",
    "\n",
    "    return vectors, labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {
    "id": "NCCXtDpcugmd"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<html>\n",
       "<head><meta charset=\"utf-8\" /></head>\n",
       "<body>\n",
       "    <div>            <script src=\"https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/MathJax.js?config=TeX-AMS-MML_SVG\"></script><script type=\"text/javascript\">if (window.MathJax && window.MathJax.Hub && window.MathJax.Hub.Config) {window.MathJax.Hub.Config({SVG: {font: \"STIX-Web\"}});}</script>                <script type=\"text/javascript\">window.PlotlyConfig = {MathJaxConfig: 'local'};</script>\n",
       "        <script charset=\"utf-8\" src=\"https://cdn.plot.ly/plotly-3.0.1.min.js\"></script>                <div id=\"467f9e79-4fbf-42e1-a88e-e9a26eb371f0\" class=\"plotly-graph-div\" style=\"height:525px; width:100%;\"></div>            <script type=\"text/javascript\">                window.PLOTLYENV=window.PLOTLYENV || {};                                if (document.getElementById(\"467f9e79-4fbf-42e1-a88e-e9a26eb371f0\")) {                    Plotly.newPlot(                        \"467f9e79-4fbf-42e1-a88e-e9a26eb371f0\",                        [{\"hovertemplate\":\"x=%{x}\\u003cbr\\u003ey=%{y}\\u003cbr\\u003etext=%{text}\\u003cextra\\u003e\\u003c\\u002fextra\\u003e\",\"legendgroup\":\"\",\"marker\":{\"color\":\"#636efa\",\"symbol\":\"circle\"},\"mode\":\"markers+text\",\"name\":\"\",\"orientation\":\"v\",\"showlegend\":false,\"text\":[\"que\",\"y\",\"el\",\"la\",\"de\",\"a\",\"en\",\"me\",\"no\",\"un\",\"se\",\"los\",\"lo\",\"al\",\"las\",\"con\",\"le\",\"como\",\"una\",\"yo\",\"m\\u00e1s\",\"ni\",\"si\",\"es\",\"mi\",\"por\",\"pa\",\"sin\",\"su\",\"gaucho\",\"era\",\"pero\",\"cuando\",\"ya\",\"del\",\"nos\",\"para\",\"hab\\u00eda\",\"aunque\",\"hay\",\"pues\",\"o\",\"he\",\"hombre\",\"hasta\",\"ans\\u00ed\",\"vez\",\"otro\",\"uno\",\"tan\",\"qu\\u00e9\",\"ha\",\"sus\",\"siempre\",\"les\",\"entre\",\"\\u00e9l\",\"dende\",\"d\\u00eda\",\"all\\u00ed\",\"mesmo\",\"cuanto\",\"ay\",\"suerte\",\"todo\",\"mis\",\"soy\",\"medio\",\"naides\",\"porque\",\"nunca\",\"ande\",\"amigo\",\"dio\",\"tiene\",\"esa\",\"pobre\",\"dios\",\"gente\",\"despu\\u00e9s\",\"son\",\"ten\\u00eda\",\"tal\",\"aquel\",\"dije\",\"s\\u00e9\",\"nada\",\"estaba\",\"dos\",\"mujer\",\"vida\",\"cantar\",\"ocasi\\u00f3n\",\"bien\",\"tierra\",\"otros\",\"noche\",\"cosa\",\"ver\",\"fin\",\"mal\",\"ser\",\"tanto\",\"ninguno\",\"poncho\",\"muy\",\"andaba\",\"mas\",\"s\\u00f3lo\",\"este\",\"campo\",\"alg\\u00fan\",\"males\",\"punto\",\"vino\",\"iba\",\"dijo\",\"esto\",\"visto\",\"hijos\",\"todos\",\"poco\",\"tener\",\"andar\",\"esta\",\"ust\\u00e9\",\"lao\",\"mundo\",\"fierro\",\"cruz\",\"tengo\",\"veces\",\"sabe\",\"rancho\",\"tiempo\",\"m\\u00ed\",\"sufrir\",\"han\",\"hac\\u00eda\",\"mano\",\"aqu\\u00ed\",\"aquella\",\"hice\",\"venga\",\"coraz\\u00f3n\",\"\\u00a1qu\\u00e9\",\"hacienda\",\"c\\u00f3mo\",\"tantos\",\"entonces\",\"tambi\\u00e9n\",\"hace\",\"mientras\",\"anda\",\"pago\",\"mejor\",\"hago\",\"dar\",\"muerto\",\"hizo\",\"alma\",\"juez\",\"cosas\",\"ese\",\"ojos\",\"hab\\u00edan\",\"sobre\",\"donde\",\"hacen\",\"indio\",\"quiera\",\"te\",\"ech\\u00e9\",\"gringo\",\"quise\",\"unos\",\"lanza\",\"cada\",\"viento\",\"cuero\",\"cantando\",\"sido\",\"penas\",\"hacer\",\"ellos\",\"indios\",\"jue\",\"eso\",\"pronto\",\"va\",\"triste\",\"muchos\",\"sal\\u00ed\",\"cant\\u00f3n\",\"all\\u00e1\",\"est\\u00e1\",\"buscar\",\"fac\\u00f3n\",\"pie\",\"agua\"],\"x\":{\"dtype\":\"f4\",\"bdata\":\"UlwnPyenLUA5rbW+oylpwHL4BEH+iPq\\u002fErfPQAzyAUHsFfJA95KnQPp2ssAdtltA1YWkvu6opEDkdh0\\u002f2lQJwUXvh0CbkqLAZ7ZgQTgynUGv2hJAYwXGQEbjGEERPTpBC0YvQcfOYUDwh5NAbB7uQAWwIkHb7gpBk9mIP0EBM0EYq3M+9C83wJ9O\\u002fkDrAMhAV6gzQYVVB0A2GTRBS47WwBusTEE5in5BvEIYQaq6+r8+1EdAF2I7wM\\u002f3gUFgZkpA6icFQVn+PkFaEnZBhZsXQRzUNUARxeBAkFeGQdKdukC+aRJAwucfQSgTi0GuVQHBCOowv6CrS8CCYvrAwkL9PxGq5UAqh3lA+GhFQSXomEETqwdBK51gQUPbLD+vJGFB1L54Qc7gt8ChxBZBiIthQZDhuEAXjBY\\u002f+VPawJQFIsFrSNRAdMW9wPNAd0FzpgtBCai3QBAlhkHnWmtBEf5NQTE0okDA8CpBb7dQQcLgUEDMBoVBPfSMwAa4TEF12KJAYjd5QYQHKMFpgTg\\u002f9TLuPyUpIkGypptAoQoYQSaYFEGpYhvAVuIHQXtmUsC25oRBSiWZQGbFbEEH4wZAYqRXQQJ8nD9S2O0\\u002f8P8RwfHefUFZMQNBVYyMQdDLokHCeRtBto1yQeIbkkH63JlBAO2QQcL7JkGm0GZBYqHovyeiWEHJGhZBWfzyQJ6Oir9k6BBBoGBwv3v7X0GognZBk+aRQAxIWb5YlgbA7sC6wGtrgMCw3vy\\u002fRxOQwCijz75mG1ZB7N1APzLDh0EDon+\\u002fhjugQCCwd0FjRFhBJsQpQXZdhT24dAhA5wtRQaGWa0Fj9ei\\u002ftuVnQMhDIkEzyolB0rEOweedlUAV+8hAvTInwSzPYkHPKK1AhjkRwYH\\u002fH0GeE8hA\\u002fLAxwf4uDj\\u002fmZHpBn3WRQUkI1z8LxOlAfh7SwA7dIME42kvBV75dPm2xCcFFWlXBnh6UQTFloEF2ry5BZPsLwD0chcA6OIVBO1WDQZNCeMD6gMlAaBxMQRF1PUHr5yTALZEGQPnEesFY2qlAYwldQfpzd0H9o9pAZmOIwNk0ecE=\"},\"xaxis\":\"x\",\"y\":{\"dtype\":\"f4\",\"bdata\":\"iHvkQKR3a0CjO5xAtirEQFD9kT7mxfNAswkRv89Izz6IB\\u002fpAEPiVwGaxKUA27NVAiMrNQOlypkDARRBBrzs5vk5JCEFkPtTA2KIxQd83xj9imdDAQqU+wPHxmECB1C1B\\u002f\\u002f4OQbyStEAHmNO\\u002f3gyUQBZz+j1fCRDAltlUQPvYUEAQNCBAWKR5QMiQlb+pQxxB0MfqQAWWDEDWCq2+GEF3QOTbRb8uLiNBa8osQQooFkCEdJDANnOtwKKnJEFtiyrAAEjyQImeA0CzzO1AsT4rQSoY9EDzLKDAKUYBv6cs+0DE8g1BWOh\\u002fwLwDyj9moQ1AOPFdQDHHg8B1tzE\\u002fPZWIQLw26b8pCCBBwK28QEUxtD6pgBBBITjCvomTpMAQiNNAvZ24vzElsEAXAC\\u002fA+7kyQTBOwr+9T5m+36LuwOh2jL5LPtlAbo\\u002fHwEXuLEE9ikfAeKlqvvZt8kBbchE\\u002fCTUbQbpN5UCT8KxAehn1QP7hjUCPCq8\\u002fBew\\u002fQIKl\\u002fUAkTAxAGiYjPz507r\\u002fKWNs\\u002fg44EwPGPsL9w90DAVkqtPzjQGT+gQNU\\u002fHC3JQHXmyECkH89A0M0DvwtDTkCFA79Ap+A1wNWugsDpXrtAOkaNv5W73UBLJKtAGKzMPsMaKkBTDfdAvdQgQGL28kCe7DlAqITsQGRm5T+twxFBnHi0QI98lUBPJyC\\u002f7YlKwPZDs8ApjUBA7GvjP61fwUD7uhNB2E74QBDtiT+sAYLAmJPMPw6Fp0AdNYBAp9L+v59MZsAFTjPA5rkpwHaUHkDWWCW\\u002fxBawP60PpUAJyBRALzHWQFBaakB6fqA\\u002ffYV7QE60wEB39B4\\u002fW\\u002f6IQLkBVUAwbVBA3AHswKAJqj4ABBxBcMLmwKEn+T8kXfBAOwDIwEnhC0CFL45AH5HowBDf10BhtR1BHhUcQCQhXr8YRcVAO4VeQBWYyMC2ZwXBTZyjQBWrDsCa4lvASWwHQMpuNUBPHtZAoPjZQJColcDWMedAOmspQPVS0b9bi6VAd1gNP9bGeD\\u002f3oz+8tcuSv4XKqMCFb1tA6N2YPwMK2EAIB4A+eEZqv+MX98A=\"},\"yaxis\":\"y\",\"type\":\"scatter\"}],                        {\"template\":{\"data\":{\"histogram2dcontour\":[{\"type\":\"histogram2dcontour\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"choropleth\":[{\"type\":\"choropleth\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}],\"histogram2d\":[{\"type\":\"histogram2d\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"heatmap\":[{\"type\":\"heatmap\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"contourcarpet\":[{\"type\":\"contourcarpet\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}],\"contour\":[{\"type\":\"contour\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"surface\":[{\"type\":\"surface\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"mesh3d\":[{\"type\":\"mesh3d\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}],\"scatter\":[{\"fillpattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2},\"type\":\"scatter\"}],\"parcoords\":[{\"type\":\"parcoords\",\"line\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatterpolargl\":[{\"type\":\"scatterpolargl\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"bar\":[{\"error_x\":{\"color\":\"#2a3f5f\"},\"error_y\":{\"color\":\"#2a3f5f\"},\"marker\":{\"line\":{\"color\":\"#E5ECF6\",\"width\":0.5},\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"bar\"}],\"scattergeo\":[{\"type\":\"scattergeo\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatterpolar\":[{\"type\":\"scatterpolar\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"histogram\":[{\"marker\":{\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"histogram\"}],\"scattergl\":[{\"type\":\"scattergl\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatter3d\":[{\"type\":\"scatter3d\",\"line\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scattermap\":[{\"type\":\"scattermap\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scattermapbox\":[{\"type\":\"scattermapbox\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatterternary\":[{\"type\":\"scatterternary\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scattercarpet\":[{\"type\":\"scattercarpet\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"carpet\":[{\"aaxis\":{\"endlinecolor\":\"#2a3f5f\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"minorgridcolor\":\"white\",\"startlinecolor\":\"#2a3f5f\"},\"baxis\":{\"endlinecolor\":\"#2a3f5f\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"minorgridcolor\":\"white\",\"startlinecolor\":\"#2a3f5f\"},\"type\":\"carpet\"}],\"table\":[{\"cells\":{\"fill\":{\"color\":\"#EBF0F8\"},\"line\":{\"color\":\"white\"}},\"header\":{\"fill\":{\"color\":\"#C8D4E3\"},\"line\":{\"color\":\"white\"}},\"type\":\"table\"}],\"barpolar\":[{\"marker\":{\"line\":{\"color\":\"#E5ECF6\",\"width\":0.5},\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"barpolar\"}],\"pie\":[{\"automargin\":true,\"type\":\"pie\"}]},\"layout\":{\"autotypenumbers\":\"strict\",\"colorway\":[\"#636efa\",\"#EF553B\",\"#00cc96\",\"#ab63fa\",\"#FFA15A\",\"#19d3f3\",\"#FF6692\",\"#B6E880\",\"#FF97FF\",\"#FECB52\"],\"font\":{\"color\":\"#2a3f5f\"},\"hovermode\":\"closest\",\"hoverlabel\":{\"align\":\"left\"},\"paper_bgcolor\":\"white\",\"plot_bgcolor\":\"#E5ECF6\",\"polar\":{\"bgcolor\":\"#E5ECF6\",\"angularaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"radialaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"}},\"ternary\":{\"bgcolor\":\"#E5ECF6\",\"aaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"baxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"caxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"}},\"coloraxis\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"colorscale\":{\"sequential\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"sequentialminus\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"diverging\":[[0,\"#8e0152\"],[0.1,\"#c51b7d\"],[0.2,\"#de77ae\"],[0.3,\"#f1b6da\"],[0.4,\"#fde0ef\"],[0.5,\"#f7f7f7\"],[0.6,\"#e6f5d0\"],[0.7,\"#b8e186\"],[0.8,\"#7fbc41\"],[0.9,\"#4d9221\"],[1,\"#276419\"]]},\"xaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\",\"title\":{\"standoff\":15},\"zerolinecolor\":\"white\",\"automargin\":true,\"zerolinewidth\":2},\"yaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\",\"title\":{\"standoff\":15},\"zerolinecolor\":\"white\",\"automargin\":true,\"zerolinewidth\":2},\"scene\":{\"xaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\",\"gridwidth\":2},\"yaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\",\"gridwidth\":2},\"zaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\",\"gridwidth\":2}},\"shapedefaults\":{\"line\":{\"color\":\"#2a3f5f\"}},\"annotationdefaults\":{\"arrowcolor\":\"#2a3f5f\",\"arrowhead\":0,\"arrowwidth\":1},\"geo\":{\"bgcolor\":\"white\",\"landcolor\":\"#E5ECF6\",\"subunitcolor\":\"white\",\"showland\":true,\"showlakes\":true,\"lakecolor\":\"white\"},\"title\":{\"x\":0.05},\"mapbox\":{\"style\":\"light\"}}},\"xaxis\":{\"anchor\":\"y\",\"domain\":[0.0,1.0],\"title\":{\"text\":\"x\"}},\"yaxis\":{\"anchor\":\"x\",\"domain\":[0.0,1.0],\"title\":{\"text\":\"y\"}},\"legend\":{\"tracegroupgap\":0},\"margin\":{\"t\":60}},                        {\"responsive\": true}                    ).then(function(){\n",
       "                            \n",
       "var gd = document.getElementById('467f9e79-4fbf-42e1-a88e-e9a26eb371f0');\n",
       "var x = new MutationObserver(function (mutations, observer) {{\n",
       "        var display = window.getComputedStyle(gd).display;\n",
       "        if (!display || display === 'none') {{\n",
       "            console.log([gd, 'removed!']);\n",
       "            Plotly.purge(gd);\n",
       "            observer.disconnect();\n",
       "        }}\n",
       "}});\n",
       "\n",
       "// Listen for the removal of the full notebook cells\n",
       "var notebookContainer = gd.closest('#notebook-container');\n",
       "if (notebookContainer) {{\n",
       "    x.observe(notebookContainer, {childList: true});\n",
       "}}\n",
       "\n",
       "// Listen for the clearing of the current output cell\n",
       "var outputEl = gd.closest('.output');\n",
       "if (outputEl) {{\n",
       "    x.observe(outputEl, {childList: true});\n",
       "}}\n",
       "\n",
       "                        })                };            </script>        </div>\n",
       "</body>\n",
       "</html>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Graficar los embedddings en 2D\n",
    "import plotly.graph_objects as go\n",
    "import plotly.express as px\n",
    "\n",
    "vecs, labels = reduce_dimensions(w2v_model)\n",
    "\n",
    "MAX_WORDS=200\n",
    "fig = px.scatter(x=vecs[:MAX_WORDS,0], y=vecs[:MAX_WORDS,1], text=labels[:MAX_WORDS])\n",
    "fig.show(renderer=\"colab\") # esto para plotly en colab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<html>\n",
       "<head><meta charset=\"utf-8\" /></head>\n",
       "<body>\n",
       "    <div>            <script src=\"https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/MathJax.js?config=TeX-AMS-MML_SVG\"></script><script type=\"text/javascript\">if (window.MathJax && window.MathJax.Hub && window.MathJax.Hub.Config) {window.MathJax.Hub.Config({SVG: {font: \"STIX-Web\"}});}</script>                <script type=\"text/javascript\">window.PlotlyConfig = {MathJaxConfig: 'local'};</script>\n",
       "        <script charset=\"utf-8\" src=\"https://cdn.plot.ly/plotly-3.0.1.min.js\"></script>                <div id=\"f5f8aa68-73d4-414a-8b17-d041b3a93145\" class=\"plotly-graph-div\" style=\"height:525px; width:100%;\"></div>            <script type=\"text/javascript\">                window.PLOTLYENV=window.PLOTLYENV || {};                                if (document.getElementById(\"f5f8aa68-73d4-414a-8b17-d041b3a93145\")) {                    Plotly.newPlot(                        \"f5f8aa68-73d4-414a-8b17-d041b3a93145\",                        [{\"hovertemplate\":\"x=%{x}\\u003cbr\\u003ey=%{y}\\u003cbr\\u003ez=%{z}\\u003cbr\\u003etext=%{text}\\u003cextra\\u003e\\u003c\\u002fextra\\u003e\",\"legendgroup\":\"\",\"marker\":{\"color\":\"#636efa\",\"symbol\":\"circle\",\"size\":2},\"mode\":\"markers+text\",\"name\":\"\",\"scene\":\"scene\",\"showlegend\":false,\"text\":[\"que\",\"y\",\"el\",\"la\",\"de\",\"a\",\"en\",\"me\",\"no\",\"un\",\"se\",\"los\",\"lo\",\"al\",\"las\",\"con\",\"le\",\"como\",\"una\",\"yo\",\"m\\u00e1s\",\"ni\",\"si\",\"es\",\"mi\",\"por\",\"pa\",\"sin\",\"su\",\"gaucho\",\"era\",\"pero\",\"cuando\",\"ya\",\"del\",\"nos\",\"para\",\"hab\\u00eda\",\"aunque\",\"hay\",\"pues\",\"o\",\"he\",\"hombre\",\"hasta\",\"ans\\u00ed\",\"vez\",\"otro\",\"uno\",\"tan\",\"qu\\u00e9\",\"ha\",\"sus\",\"siempre\",\"les\",\"entre\",\"\\u00e9l\",\"dende\",\"d\\u00eda\",\"all\\u00ed\",\"mesmo\",\"cuanto\",\"ay\",\"suerte\",\"todo\",\"mis\",\"soy\",\"medio\",\"naides\",\"porque\",\"nunca\",\"ande\",\"amigo\",\"dio\",\"tiene\",\"esa\",\"pobre\",\"dios\",\"gente\",\"despu\\u00e9s\",\"son\",\"ten\\u00eda\",\"tal\",\"aquel\",\"dije\",\"s\\u00e9\",\"nada\",\"estaba\",\"dos\",\"mujer\",\"vida\",\"cantar\",\"ocasi\\u00f3n\",\"bien\",\"tierra\",\"otros\",\"noche\",\"cosa\",\"ver\",\"fin\",\"mal\",\"ser\",\"tanto\",\"ninguno\",\"poncho\",\"muy\",\"andaba\",\"mas\",\"s\\u00f3lo\",\"este\",\"campo\",\"alg\\u00fan\",\"males\",\"punto\",\"vino\",\"iba\",\"dijo\",\"esto\",\"visto\",\"hijos\",\"todos\",\"poco\",\"tener\",\"andar\",\"esta\",\"ust\\u00e9\",\"lao\",\"mundo\",\"fierro\",\"cruz\",\"tengo\",\"veces\",\"sabe\",\"rancho\",\"tiempo\",\"m\\u00ed\",\"sufrir\",\"han\",\"hac\\u00eda\",\"mano\",\"aqu\\u00ed\",\"aquella\",\"hice\",\"venga\",\"coraz\\u00f3n\",\"\\u00a1qu\\u00e9\",\"hacienda\",\"c\\u00f3mo\",\"tantos\",\"entonces\",\"tambi\\u00e9n\",\"hace\",\"mientras\",\"anda\",\"pago\",\"mejor\",\"hago\",\"dar\",\"muerto\",\"hizo\",\"alma\",\"juez\",\"cosas\",\"ese\",\"ojos\",\"hab\\u00edan\",\"sobre\",\"donde\",\"hacen\",\"indio\",\"quiera\",\"te\",\"ech\\u00e9\",\"gringo\",\"quise\",\"unos\",\"lanza\",\"cada\",\"viento\",\"cuero\",\"cantando\",\"sido\",\"penas\",\"hacer\",\"ellos\",\"indios\",\"jue\",\"eso\",\"pronto\",\"va\",\"triste\",\"muchos\",\"sal\\u00ed\",\"cant\\u00f3n\",\"all\\u00e1\",\"est\\u00e1\",\"buscar\",\"fac\\u00f3n\",\"pie\",\"agua\"],\"x\":{\"dtype\":\"f4\",\"bdata\":\"76X+QJwkXEFeKE0\\u002f5n4nwFhHmEHV7\\u002fJAYmaiQRMah0HY6vBAxmEiwH5D2sAM8wFACJE4wF9XFUFDjCbAOqaxwbClhkFSGuXBNQA2QiRNekLZU2zBrhOqQaaT1kExo\\u002f5Bk+r\\u002fQRdTsMDP401BulBqQZ8Oz0F4C4RBJWiRwR2zEELn4QJB1BqoQNGSeUF\\u002fsYBBMgDJQaWOrT9G\\u002fg1ChmcBwVGZEkIImi5CmvO7QSdFzz4T6oTBkR2OwTxnJEL0UL9AeuXeQWloCUK4RyFC5ZexQcRlDkBvaOVBf31ZQgq7E0HfhWxBoBqUQbalLkJJGY\\u002fBXFkYv1x7FcFllsTB53ENQTyoH0E+S8pBYg3UQUm6VEIuMKJBxBvdQQjgl8Gh0CxCKgAyQqy\\u002fkD61ENBBrY9OQo\\u002fLMUEMqbnAwUJ5wdlCscGo0YxBLz6RwSptQkKxIYxBtFjqQKzOTEIWHzVCD10eQlat1kAXOARCxHoOQrzCEr91c1xCnHUMwYGe7EF8Em9BPCBBQreN2MH+jgRBVh+OQGhmzEHrCKfAMdbDQWPzyUGqAkg\\u002f92O5QR5ni782pEtCIeEjQQEwGkITODpBd4QXQl0t58CEUQVBnL\\u002fYwSpIREITXolBSyFnQqhHg0Kxg29BRBYWQrYgFUID831C08odQmic60FPgw5CJyhLPlOz6kG059FBwj21QWMGN0AQH7ZBYHNxPSy4IUI8jSZChr9QQf5+m8E4g1XBUyaRwEqhN8C7MBTBZG1vwXff5D0FagFCUZ+PwFktUEJ\\u002fSRfBn8wrQTugHUIOfBZCdH29QVMBS0CPWpw\\u002fvqb5QRfzQEKGSwjBM7wCQFK\\u002f2kEEAFNCw6PcwYuwSUDwJ4RBcQIewhYdKkLayghBRmu7wXOu3UEy84tBeyb5wSccckCbCTdC1jZXQiPf\\u002fUCM131ByYotwYDU4sEIGT\\u002fCWQYPwcCB7cBWdhvCBjBkQhgnekKfKrhBOJ1SQK5ErcF\\u002f\\u002fEBCHuRIQrayfMHrInVBF3kOQh0+7UFJm5DBxjmCQGSVLMKjnxRBvbs1Qn2yLkJPPZ9B5OQAwRoAG8I=\"},\"y\":{\"dtype\":\"f4\",\"bdata\":\"GHaYwLmVwkChygBBv8kNQMqyDMInwxDASvF7Qefy4sH1ZcfBsv94wUilHEJ+3l\\u002fBl332wCN1m8HaDefBSWtSwXV9wsEndphBWgtgQTV+wL8NetnBKQZBQWuVXUCQWbxBJ+VMwD5K88HrM8VBzoq1QItlqUHtobZB5FLZwX\\u002fdW8EWOYlBL5gCQlrn5cExGGlB\\u002f5L2v6QKLcELwcVBz6unwS6FlMGhZihAfSpywX85rUF6OgvBawdgwdmemj+aJOJBrkvTwYP6sUAelYzBKHJEwbn0zsGfhf5B2UfCwRQymcEKZONAYm3rQdGKwUD0ZwFCTVd2QdW4D0LukXfBtowpwLBNSUFjYa7BCb8JweGUUEEuiA9ATii5wcItSUF1+8vAC7iEQWdlBUJdAO9BMqFPQSNHkkCC6QrB+lOkQHvCF0LcUnfBZQcnwDuf8UAAKP1BTsoHQkM9vcGR6BHB+sxWQeu71sHpvkNBlUA8QZVMY8EmLCLB77SdwVQwQUGlUfDBLjSHwUsJ8kHao\\u002fzB0dSqQc6ajEEEMHtAD3epwdEZBMJPYbtBt\\u002fCRwA8He8ATd4vBWu6uQTCyF0HYY4ZBugEHwlgpuME8LKBBrXn8Qc\\u002fvasEowz1BoFtHwVPZ6kBcbRHBV8nIwWa+zcHTClXAUgCrwcu8VkHB53E\\u002f171Nv4oRzj\\u002fRZaVBqbvQQWjMEUGRBitAKjkpQWg8MT8xCYXA+gjcwcbrFMG0Z0XBgFjmQSJqH0GhbcnAX6gBwZDmMkHcDQPClFwNwQ6gUr7D2xjBmQCKwW7A+8Au2GrBucpswUs7IEFmJEjBij1TwSROH8D5N7lAQcAZwaLqWcE4ICpBWV5yQYxW4cFSEotB91rQQXXVsMEwXZPByIWZQVceMEGE5kPByHoBQafxI8CszaY\\u002fcfWqvzwRZEEkjcw+MkWOwTKJTcB6FlNBkewTQId\\u002f0kH7jrbAC1KaQLCQfUB+iQjB4it\\u002fQDYXyD9wvLPBF0OiwFYCNcDDEGXAV31dQZyYNEH4sE7BYNVZQWzc9cCoSZjBtTqWwULNWcGY1blBSR6wQYA0i0A=\"},\"z\":{\"dtype\":\"f4\",\"bdata\":\"ElwaQobmsUFqxAxCOSsBwvh0hb+hAODBgmqlQdjbacBhWVXAL\\u002fcSwn4VOECihbvBy2cGQi1GqEFJFVxAkB8\\u002fwR81ssEDgZFBptKNwdWmMsEuhMG\\u002fxtqcweBVnMGi+olBcpgDQntd0cCqDgjBlheZQF1oxcGFgiBBge\\u002fuQC\\u002fTcMEbZERBX\\u002fFCwaBowEERdxnB5\\u002fPxwYx7jUG9zAu\\u002fBNzDQf7lucEgTcPBOIoHQrP4dkFdDvFBl3TWwWQT6cF8BL6\\u002fYQGawWgt2r9ijshB4ajqQYnMPMHjFUnB86RGwMi67sGMkvrB9UWWQVou5L\\u002fbYAtBK2XXQd8YJ8EHkmc+hW3SQZRO9UG0RuDAsl5gQafx\\u002fUC\\u002frwxClk3BQUrF60H3k+xBm15Yv0jMRUH2pBFB7QWFwfjXXMFl7yxAEvUEwkuKvsBR43rBbb6ewUA0vMFeu6dAYtZCQWmcvUEOGTHB7Qohwbm6scGuHZPBq1HdQTuaWMH+bGfB7IHPPyJj7kEMakhBwRGSwcPRzcFKhYRAwu4uwaNVEkGbziRCC9E+QUx8IMGmyvfBY6SnQUgv7cFEEHdBzYe2Qdm6jEH\\u002fcc7BLX5NP9UKsMG7SKHBIlmrvrwExkGnhThB3odJwCWdOsCLUNnBuLQbwZ7OhUETpfe\\u002fhildQabTCsD9b5vBiV+QwWBDr0Eb5\\u002frAccqOv6XOWcHZlr9AHaeIQX1sx0EsVp3Brn1nwUlej0EiWX\\u002fBHCjXQEE288EkPtfBMI5RP5dYR0BTpFk\\u002fx9SYwWXSJj+BsjtBE\\u002f\\u002f6QZT8iUFSuOs\\u002fWfLLwQXb1kEhModA\\u002f06fQVKUsEGCMadBjAaQwXa3ZsHJljzA7XkMwlmpcEHG1D7AaHwgwepAEz5mfb7BBrbVwTCSFsGIUJdB+LeTP4dQC0KgJ5bBHoLrwAUDkEChWanBqf2dQd1+z8Fn6sjBEPj9QX5ejsFdyp7BPCAPwVarnz48ErzBNwjJwat6mEF1I5ZBCkd+QORhsUAP5JVBIcXkQIw2fEHGLgxBh22HwGdCb8ELuRLAykL9wJdBrUE7iYTB5lGFQKwba0A=\"},\"type\":\"scatter3d\"}],                        {\"template\":{\"data\":{\"histogram2dcontour\":[{\"type\":\"histogram2dcontour\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"choropleth\":[{\"type\":\"choropleth\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}],\"histogram2d\":[{\"type\":\"histogram2d\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"heatmap\":[{\"type\":\"heatmap\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"contourcarpet\":[{\"type\":\"contourcarpet\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}],\"contour\":[{\"type\":\"contour\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"surface\":[{\"type\":\"surface\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"mesh3d\":[{\"type\":\"mesh3d\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}],\"scatter\":[{\"fillpattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2},\"type\":\"scatter\"}],\"parcoords\":[{\"type\":\"parcoords\",\"line\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatterpolargl\":[{\"type\":\"scatterpolargl\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"bar\":[{\"error_x\":{\"color\":\"#2a3f5f\"},\"error_y\":{\"color\":\"#2a3f5f\"},\"marker\":{\"line\":{\"color\":\"#E5ECF6\",\"width\":0.5},\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"bar\"}],\"scattergeo\":[{\"type\":\"scattergeo\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatterpolar\":[{\"type\":\"scatterpolar\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"histogram\":[{\"marker\":{\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"histogram\"}],\"scattergl\":[{\"type\":\"scattergl\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatter3d\":[{\"type\":\"scatter3d\",\"line\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scattermap\":[{\"type\":\"scattermap\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scattermapbox\":[{\"type\":\"scattermapbox\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatterternary\":[{\"type\":\"scatterternary\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scattercarpet\":[{\"type\":\"scattercarpet\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"carpet\":[{\"aaxis\":{\"endlinecolor\":\"#2a3f5f\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"minorgridcolor\":\"white\",\"startlinecolor\":\"#2a3f5f\"},\"baxis\":{\"endlinecolor\":\"#2a3f5f\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"minorgridcolor\":\"white\",\"startlinecolor\":\"#2a3f5f\"},\"type\":\"carpet\"}],\"table\":[{\"cells\":{\"fill\":{\"color\":\"#EBF0F8\"},\"line\":{\"color\":\"white\"}},\"header\":{\"fill\":{\"color\":\"#C8D4E3\"},\"line\":{\"color\":\"white\"}},\"type\":\"table\"}],\"barpolar\":[{\"marker\":{\"line\":{\"color\":\"#E5ECF6\",\"width\":0.5},\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"barpolar\"}],\"pie\":[{\"automargin\":true,\"type\":\"pie\"}]},\"layout\":{\"autotypenumbers\":\"strict\",\"colorway\":[\"#636efa\",\"#EF553B\",\"#00cc96\",\"#ab63fa\",\"#FFA15A\",\"#19d3f3\",\"#FF6692\",\"#B6E880\",\"#FF97FF\",\"#FECB52\"],\"font\":{\"color\":\"#2a3f5f\"},\"hovermode\":\"closest\",\"hoverlabel\":{\"align\":\"left\"},\"paper_bgcolor\":\"white\",\"plot_bgcolor\":\"#E5ECF6\",\"polar\":{\"bgcolor\":\"#E5ECF6\",\"angularaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"radialaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"}},\"ternary\":{\"bgcolor\":\"#E5ECF6\",\"aaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"baxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"caxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"}},\"coloraxis\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"colorscale\":{\"sequential\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"sequentialminus\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"diverging\":[[0,\"#8e0152\"],[0.1,\"#c51b7d\"],[0.2,\"#de77ae\"],[0.3,\"#f1b6da\"],[0.4,\"#fde0ef\"],[0.5,\"#f7f7f7\"],[0.6,\"#e6f5d0\"],[0.7,\"#b8e186\"],[0.8,\"#7fbc41\"],[0.9,\"#4d9221\"],[1,\"#276419\"]]},\"xaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\",\"title\":{\"standoff\":15},\"zerolinecolor\":\"white\",\"automargin\":true,\"zerolinewidth\":2},\"yaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\",\"title\":{\"standoff\":15},\"zerolinecolor\":\"white\",\"automargin\":true,\"zerolinewidth\":2},\"scene\":{\"xaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\",\"gridwidth\":2},\"yaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\",\"gridwidth\":2},\"zaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\",\"gridwidth\":2}},\"shapedefaults\":{\"line\":{\"color\":\"#2a3f5f\"}},\"annotationdefaults\":{\"arrowcolor\":\"#2a3f5f\",\"arrowhead\":0,\"arrowwidth\":1},\"geo\":{\"bgcolor\":\"white\",\"landcolor\":\"#E5ECF6\",\"subunitcolor\":\"white\",\"showland\":true,\"showlakes\":true,\"lakecolor\":\"white\"},\"title\":{\"x\":0.05},\"mapbox\":{\"style\":\"light\"}}},\"scene\":{\"domain\":{\"x\":[0.0,1.0],\"y\":[0.0,1.0]},\"xaxis\":{\"title\":{\"text\":\"x\"}},\"yaxis\":{\"title\":{\"text\":\"y\"}},\"zaxis\":{\"title\":{\"text\":\"z\"}}},\"legend\":{\"tracegroupgap\":0},\"margin\":{\"t\":60}},                        {\"responsive\": true}                    ).then(function(){\n",
       "                            \n",
       "var gd = document.getElementById('f5f8aa68-73d4-414a-8b17-d041b3a93145');\n",
       "var x = new MutationObserver(function (mutations, observer) {{\n",
       "        var display = window.getComputedStyle(gd).display;\n",
       "        if (!display || display === 'none') {{\n",
       "            console.log([gd, 'removed!']);\n",
       "            Plotly.purge(gd);\n",
       "            observer.disconnect();\n",
       "        }}\n",
       "}});\n",
       "\n",
       "// Listen for the removal of the full notebook cells\n",
       "var notebookContainer = gd.closest('#notebook-container');\n",
       "if (notebookContainer) {{\n",
       "    x.observe(notebookContainer, {childList: true});\n",
       "}}\n",
       "\n",
       "// Listen for the clearing of the current output cell\n",
       "var outputEl = gd.closest('.output');\n",
       "if (outputEl) {{\n",
       "    x.observe(outputEl, {childList: true});\n",
       "}}\n",
       "\n",
       "                        })                };            </script>        </div>\n",
       "</body>\n",
       "</html>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Graficar los embedddings en 3D\n",
    "\n",
    "vecs, labels = reduce_dimensions(w2v_model,3)\n",
    "\n",
    "fig = px.scatter_3d(x=vecs[:MAX_WORDS,0], y=vecs[:MAX_WORDS,1], z=vecs[:MAX_WORDS,2],text=labels[:MAX_WORDS])\n",
    "fig.update_traces(marker_size = 2)\n",
    "fig.show(renderer=\"colab\") # esto para plotly en colab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "# También se pueden guardar los vectores y labels como tsv para graficar en\n",
    "# http://projector.tensorflow.org/\n",
    "\n",
    "\n",
    "vectors = np.asarray(w2v_model.wv.vectors)\n",
    "labels = list(w2v_model.wv.index_to_key)\n",
    "\n",
    "np.savetxt(\"vectors.tsv\", vectors, delimiter=\"\\t\")\n",
    "\n",
    "with open(\"labels.tsv\", \"w\") as fp:\n",
    "    for item in labels:\n",
    "        fp.write(\"%s\\n\" % item)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('aguanta', 0.998572826385498),\n",
       " ('menos', 0.998545229434967),\n",
       " ('hoyo', 0.9985441565513611),\n",
       " ('desgraciao', 0.9985345005989075),\n",
       " ('comendante', 0.9985234141349792),\n",
       " ('güena', 0.998515248298645),\n",
       " ('anda', 0.9985134601593018),\n",
       " ('sol', 0.9985074400901794),\n",
       " ('pata', 0.9984993934631348),\n",
       " ('rigor', 0.9984962344169617)]"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "w2v_model.wv.most_similar(positive=[\"gaucho\", \"autoridá\"], negative=[\"libre\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Interpretación:\n",
    "1. aguanta, rigor, desgraciao\n",
    "Estas palabras reflejan la condición de opresión y sufrimiento. El gaucho sometido a la autoridad, privado de su libertad, es quien \"aguanta\" el \"rigor\", y se convierte en un \"desgraciao\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('jogón', 0.9991311430931091),\n",
       " ('inorancia', 0.9991233348846436),\n",
       " ('criollo', 0.9991176724433899),\n",
       " ('estrellas', 0.9991169571876526),\n",
       " ('dicen', 0.9991165399551392),\n",
       " ('alguno', 0.9991087317466736),\n",
       " ('juir', 0.9991050362586975),\n",
       " ('prendas', 0.9990985989570618),\n",
       " ('pasaba', 0.9990982413291931),\n",
       " ('siquiera', 0.9990974068641663)]"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "w2v_model.wv.most_similar(positive=[\"desgracias\", \"pobres\"], negative=[\"frontera\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Interpretación:\n",
    "2. jogón, inorancia, criollo\n",
    "Estas palabras capturan elementos del entorno y del tipo social caracterizado por la pobreza y las penurias.\n",
    "jogón (fogón rústico) alude a la vida doméstica precaria.\n",
    "inorancia (forma arcaica de ignorancia) señala la falta de educación como consecuencia de la marginalización.\n",
    "criollo puede reforzar el perfil del habitante rural y humilde."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('boca', 0.9992053508758545),\n",
       " ('negra', 0.9991989731788635),\n",
       " ('lengua', 0.9991660714149475),\n",
       " ('esas', 0.9991601705551147),\n",
       " ('falte', 0.9991515874862671),\n",
       " ('tarde', 0.999151349067688),\n",
       " ('cantor', 0.999147891998291),\n",
       " ('tres', 0.999134361743927),\n",
       " ('frontera', 0.9991329908370972),\n",
       " ('punta', 0.9991316199302673)]"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "w2v_model.wv.most_similar(positive = [\"china\", \"penas\"], negative=[\"alegría\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Interpretación:\n",
    "3. desgracias, pobres, frontera\n",
    "Estas palabras aparecen reiteradamente en contextos de miseria, exclusión y represión. El modelo parece reforzar que el sufrimiento de la “china” se vincula al entorno opresivo y marginal del universo gauchesco."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "yMM_SHSaZ9N-"
   },
   "source": [
    "### Conclusión"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "WivQZ3ZCZ9N_"
   },
   "source": [
    "El modelo, a pesar de haber sido entrenado con un corpus literario de estilo arcaico y poético, logra aprender relaciones semánticas coherentes con la narrativa del poema. No requiere de términos técnicos ni explícitos para entender:\n",
    "\n",
    "- Relación entre roles sociales (gaucho, china, coronel).\n",
    "\n",
    "- Condiciones de vida (pobreza, dolor, trabajo).\n",
    "\n",
    "- Conflictos morales y políticos (libertad vs. autoridad).\n",
    "\n",
    "Además, utiliza elementos simbólicos y culturales propios del texto, como jogón, frontera, criollo, o autoridá, para representar conceptos complejos sin necesidad de un lenguaje moderno o técnico."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "El modelo es sensible al contexto cultural y estilístico del corpus.\n",
    "\n",
    "La calidad del resultado depende de la frecuencia y el uso contextual de las palabras.\n",
    "\n",
    "Las analogías permiten explorar la \"visión de mundo\" que el modelo ha construido, y son herramientas útiles para análisis semántico, literario y cultural.\n",
    "\n",
    "Este ejercicio demuestra que incluso con un corpus literario específico, es posible entrenar modelos de lenguaje que capturen relaciones profundas y útiles para el análisis del discurso, la literatura o incluso para tareas de humanidades digitales."
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
