
# Procesamiento de Lenguaje Natural.

Este repositorio contiene el desarrollo de los **Desaf√≠os** realizados en el marco de la materia **Procesamiento de Lenguaje Natural (PLN)**, correspondiente a la **Especializaci√≥n en Inteligencia Artificial** de la **Facultad de Ingenier√≠a de la Universidad de Buenos Aires (FIUBA)**.

üë§ **Autor:** Marcelo Adri√°n M√°s Valdecantos  
üìò **C√≥digo de alumno:** a1811  

---

## Contenido del repositorio

### Desaf√≠o 1 ‚Äì Vectorizaci√≥n y Clasificaci√≥n de Textos

**Tema:**  
An√°lisis del dataset *20 Newsgroups*, utilizando t√©cnicas de vectorizaci√≥n con **TF-IDF**, clasificaci√≥n con modelos de **Na√Øve Bayes**, y estudio de **similaridad entre documentos**.

---

#### Vectorizaci√≥n y Similaridad

- Se vectoriz√≥ todo el corpus con **TF-IDF** porque permite destacar palabras importantes dentro de cada documento, restando relevancia a t√©rminos comunes en todos los textos.
- A partir del corpus, se eligieron al azar **5 documentos** y se implement√≥ el c√°lculo de **similaridad del coseno** (*cosine similarity*) para identificar los **5 documentos m√°s similares** a cada uno de ellos.
- La similaridad del coseno eval√∫a el **√°ngulo entre vectores**, interpretando cu√°n alineadas est√°n sus representaciones en el espacio vectorial.

---

#### üîπ Exploraci√≥n de Modelos de Clasificaci√≥n

Se exploraron m√∫ltiples configuraciones para optimizar el desempe√±o del modelo (F1-score macro):

1. **Modelos Na√Øve Bayes:**
   - `MultinomialNB`: adecuado para clasificaci√≥n de texto en general.
   - `ComplementNB`: dise√±ado para manejar mejor datasets con clases desbalanceadas.

2. **Par√°metros de vectorizaci√≥n (`TfidfVectorizer`):**
   - `ngram_range`: para incluir unigramas, bigramas y trigramas.
   - `min_df`: para filtrar t√©rminos poco frecuentes.
   - `stop_words`: para eliminar palabras comunes irrelevantes (e.g., en ingl√©s).

3. **Evaluaci√≥n y comparaci√≥n:**
   - Se midi√≥ el rendimiento con **F1-score macro**, que considera el equilibrio de desempe√±o entre todas las clases.
   - Se identific√≥ la **mejor combinaci√≥n de modelo y vectorizaci√≥n** que logra captar mejor el contenido del texto y optimiza la clasificaci√≥n.

---

#### ‚úÖ Conclusi√≥n

Este desaf√≠o permite observar el impacto de distintas representaciones vectoriales y par√°metros de modelos sobre el rendimiento de clasificaci√≥n en texto. Combinar m√∫ltiples configuraciones ayuda a seleccionar la opci√≥n m√°s eficaz para capturar patrones sem√°nticos y estructurales del corpus.


### 2Ô∏è Desaf√≠o 2 ‚Äì Clasificaci√≥n de Sentimientos
> **Tema:** An√°lisis de sentimientos en rese√±as de pel√≠culas.  
> Se implementan estrategias de limpieza, tokenizaci√≥n y vectorizaci√≥n para entrenar modelos supervisados que distinguen polaridad positiva/negativa.

### 3Ô∏è Desaf√≠o 3 ‚Äì Clasificaci√≥n de Texto Multiclase
> **Tema:** Construcci√≥n de modelos para clasificaci√≥n multiclase.  
>  Incluye selecci√≥n de corpus, ingenier√≠a de caracter√≠sticas, entrenamiento, evaluaci√≥n y optimizaci√≥n de modelos.

### 4Ô∏è Desaf√≠o 4 ‚Äì Sistema de Pregunta-Respuesta
> **Tema:** Desarrollo de un sistema QA (*Question Answering*) basado en modelos de lenguaje preentrenados.  
> Se trabaja con t√©cnicas avanzadas de representaci√≥n contextualizada para responder preguntas sobre un corpus espec√≠fico.

---

## Tecnolog√≠as utilizadas

- Python 3.x
- Scikit-learn
- Pandas / NumPy
- NLTK / spaCy
- Transformers (Hugging Face)
- Jupyter Notebooks

---

## Sobre la materia

La materia **Procesamiento de Lenguaje Natural (PLN)** aborda t√©cnicas, modelos y algoritmos para permitir que las m√°quinas comprendan, interpreten y generen lenguaje humano. Se estudian desde m√©todos estad√≠sticos cl√°sicos hasta modelos de aprendizaje profundo basados en redes neuronales.

---

##  Recursos complementarios

- [Documentaci√≥n de Scikit-learn](https://scikit-learn.org/stable/)
- [Gu√≠a de NLP de Hugging Face](https://huggingface.co/course/chapter1)
- [Curso de PLN de Stanford (CS224n)](http://web.stanford.edu/class/cs224n/)

---

---

## C√≥mo utilizar este repositorio

1. Clonar el repositorio o descargarlo como archivo ZIP.
2. Abrir los archivos `.ipynb` con Jupyter Notebook o Google Colab.
3. Ejecutar las celdas secuencialmente para reproducir los resultados.
4. Revisar los comentarios y outputs en cada notebook para seguir el flujo de an√°lisis.

> Es recomendable crear un entorno virtual e instalar las dependencias necesarias con `pip install -r requirements.txt` si aplica.

---

## Resumen de Resultados y Aprendizajes

- Se aplicaron diversas t√©cnicas de preprocesamiento de texto, vectorizaci√≥n y clasificaci√≥n, lo que permiti√≥ comparar enfoques cl√°sicos y modernos en PLN.
- Se experiment√≥ con **modelos supervisados**, **similaridad sem√°ntica** y **modelos de lenguaje preentrenados**.
- Se adquirieron habilidades pr√°cticas para construir pipelines de procesamiento de texto, incluyendo tareas de clasificaci√≥n, an√°lisis de sentimientos y QA.

---

##  Diagrama conceptual (proceso t√≠pico en PLN)

```mermaid
graph TD;
    A[Corpus de Texto] --> B[Preprocesamiento];
    B --> C[Vectorizaci√≥n];
    C --> D[Entrenamiento de Modelo];
    D --> E[Evaluaci√≥n];
    E --> F[Predicci√≥n / Respuesta];
```

Este diagrama representa el flujo com√∫n de trabajo aplicado en los diferentes desaf√≠os del curso.
